<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Homepage on Miao Yu | 于淼 </title>
    <link>/index.xml</link>
    <description>Recent content in Homepage on Miao Yu | 于淼 </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Feb 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>公交系统、地理学第一定律与切蛋糕</title>
      <link>/cn/2017/04/02/cake/</link>
      <pubDate>Sun, 02 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/04/02/cake/</guid>
      <description>

&lt;h2 id=&#34;公交系统&#34;&gt;公交系统&lt;/h2&gt;

&lt;p&gt;在加村的公交系统是令人发指的，且不说单程定价3.25加元跟间隔时间至少20分钟，动不动就搞罢工也让人崩溃。最近附近一个离城区20分钟车程的小镇举行枫糖节，查了半天才发现去那里的公交工作日都是一个小时一班，只是因为节日会临时加开。而且小镇内部是没有公交路线的，也就是没人引导很难找明白路，手机也基本没信号，可以说公共基础建设很差。但是当你真正进入这个小镇会发现，家家户户的房子都比城区大，后院也大，一般都放个游艇。镇子里银行、诊所、健身房、商区等服务机构一应俱全，回来后查了一下，这边房子价格中位数在36万加元，而城区价格中位数39万加元。北美这边汽车的普及率从汽车发明出来后不久就一直很高，车对于居民而言是必需品而公交系统却不是，公交系统只对底层居民、早期移民（包括留学人员）与游客是必须的，在这个大前提下很多地方不通公交是理所当然的。&lt;/p&gt;

&lt;p&gt;这点跟国内比较很不一样，例如在北京，靠近地铁跟不通公交的地方天然存在很大的价差，有时候如果房子附近被规划成地铁出口，价格瞬间就会涨起来。但这边很差劲的公交系统似乎根本不影响定价，原因也很简单，公交系统对住在这边的人没有太多的附加值。有些小镇甚至会抵制市政公交系统的渗透，除了部分居民有摩门教的信仰外，公交会把流浪汉从城市输送到小镇上，而相对富庶的小镇天然具有排外倾向，一通投票就可以把政府影响降成零，至于手机信号，同样也没必要，不欢迎你来。但如果你进入小镇，又会发现居民其实都很友善且热情好客，也就是说，你来可以，不要住下来。&lt;/p&gt;

&lt;p&gt;公交具有连通属性，但与之对应的是如果家家户户都有车，公共交通既多余又不盈利。同时，公交还让穷人有了进入富人居住地的可能，而富人又是自认善良且友善的，应对一个两个落难的人很轻松，但一车车的送过来就成了经济与道德的双重负担了。此时，小镇的民主集体投票就会展示出一个拒绝姿态，对居民是负责，对其他人呢？对不起，我压根就要从制度设计上消除你接触我的可能。也就是，地理隔离。&lt;/p&gt;

&lt;h2 id=&#34;地理学第一定律&#34;&gt;地理学第一定律&lt;/h2&gt;

&lt;p&gt;地理学是文科，但不代表文科就没有定律。加州大学圣芭芭拉分校的Waldo Tobler教授就提出了一个很模糊但又很独特的定律：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Everything is related to everything else, but near things are more related than distant things.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;不过孟子他妈可能有个更简单的成语版本来解释这个现象：孟母三迁。&lt;/p&gt;

&lt;p&gt;如果两个主体空间离得近，那就更容易产生相互影响，听上去跟废话一样，但却有出奇的解释力。世界上城市的分布大都是城市群的聚居结构的而不是均匀分布在国家领土上，也正是这种结构可以在现代社会里催生有竞争力的创新土壤，这种自发结构天然吸引人才，提供机会，推动变革。而其余星罗棋布的小城镇则基本丧失了最好的人才与劳动力，走向衰落，至于更均匀分布的乡村，不都已经工业化运作了么，社会经济结构在现代社会的影响下脆弱不堪。而那些催生聚居的东西，通常是某种资源，教育、医疗、人才甚至是矿产或港口。在钻石教授的《枪炮、病菌与钢铁》里就反复强调农作物与家畜在地理上的分布是如何导致了不同经济与文化的发展，很多制度所依赖的基础跟个人或许有关，但更多是其背后那片大陆的位置与形状。例如在相对狭长的南美大陆上气候变化很大，农作物的耕种经验就很难像横向发展的欧亚大陆那样有广泛的适用性，这样农业社会的政治经济组织关系就很难形成。&lt;/p&gt;

&lt;p&gt;不过技术的发展促进了交通的发展也就是远近的定义。如果两个地方空间距离是20公里，在走路主导的年代，这大概需要一天，而马车就把发生联系的时间缩到一个小时，而小汽车呢，大概十几二十分钟。人的工作是受生理周期限制的，每天都要睡觉休息，如果我固定每天交通时间，那么技术发展会让我可产生物理交流的空间尺度越来越大，但受限于生理而不是无限大，这个有限空间就是地理学第一定律起作用的地方。但要注意的是，这个区域之外，就是隔离。&lt;/p&gt;

&lt;p&gt;回看公交系统问题，小镇居民事实上是通过私家车享受了现代社会连通属性带来的较高的经济收入但规避了公交连通带来的城市化弊端。也就是说，地理隔离可以保障一部分人的生活质量总是高于另一部分，而那一部分人甚至意识不到高质量生活的存在，毕竟根本就可以没有让你接触的机会。但如果小镇居民的收入下降了呢，那么小镇就会被现代社会抛弃，拒绝新技术的态度会让他们失去竞争力，人口流失进而衰退。当然，此时他们会更乐于用人口优势去投出一个保守派领袖，打断国家层面与外界的联系来享受回过去的辉煌。这都是基于人性可以预测的，所有圈子内部的平等性都高于外部，利益也相对一致，当你访问一个这样的圈子时会感到里面的人都很好，经济条件也好，学识也广，能力也大。但当你想进入这个圈子时就会发现，其实其背后都是一个有限空间，进去的人也都不想出来还希望下一代继续在圈子里，因此门槛就会逐渐提高：作为外来户你看看可以，但也就是看看。这个有限空间就不仅仅是地理学上的了。&lt;/p&gt;

&lt;h2 id=&#34;切蛋糕&#34;&gt;切蛋糕&lt;/h2&gt;

&lt;p&gt;隔离会制造事实上的两个物种，两个生理上一致的物种在地理隔离下会走向生理隔离。此时很多人会跳出来说，互联网打破了地理上的隔离啊，信息传播都是瞬间的，这不就是最大的公平吗？互联网确实打破了地理隔离，但其实没有对社会层面的隔离产生太多正面影响。在A网站火的一塌糊涂的某个ID在B网站可能一个人都没听过，而A网B网的用户都可能是千万级别的。当年贴吧火爆时动不动就会出现各类爆吧，这有点类似地理空间里的游行示威，互联网只是提供了一个只需要敲打键盘就可以宣泄情感的途径，但并不解决问题。理解这个过程需要掌握一个切蛋糕的思考方法。&lt;/p&gt;

&lt;p&gt;回到公交问题，其实公交车跟私家车是潜在的竞争对手，争夺的是所有人的出行需求。对于居住密度高的大城市，其实公交系统更有利于降低城市整体交通负担。前期大放异彩的出行共享并不新鲜，所有的公交系统都是共享经济且更为节能环保，只不过私家车的自由度更高。不过国内城市住宅从一开始就基本没有house这种房型，大部分人住的基本是condo，这个人口空间集成度的住宅方式不太允许一人一辆车，能做到一家一辆已经不错了，这个条件下可共享私家车的基数本就不大，引入的共享模式最后一定会发展成类似出租车公司的模式。因此国内的人口居住行为基本就决定了必须优先发展公共交通，限制私家车并鼓励租车。短程公交或绿色出行，中远程租车可能是国内大城市出行的理性选择，私家车买了一周用不到一次的话不如考虑租车，省下车险跟车位的钱可以租更安全的车而不是买一个功能很全但一年用不上一次的车。只不过国内车还有炫耀属性，考虑那个就只能痛并快乐了。&lt;/p&gt;

&lt;p&gt;假设1000万人口城市出行日总需求1亿公里，那么蛋糕已经放好了，就看怎么切。绿色出行比例越高，大家整体健康收益越高，但具体到个人可能就会降低生活质量。同样城市的设计规划也影响蛋糕的大小，你搞了一个小区全是高层，可容纳5万人，但就设计了1千停车位，那后果要么就是小区天天爆满，要么就是住进来的都是不需要车的人，无论哪一点都会影响定价与居住意愿。例如前面的小镇，如果没有枫糖节，完全可以不建大型停车场，这样什么活动都不会规划到这边，也就实现了隔离，要知道从交通上隔离是最简单直接的封闭措施，基本上公交跟停车场的规模与建设方式一旦确定，这个地方的蛋糕就出炉了，吃蛋糕的人数也就确定了。而且割裂化的社会结构一旦形成就会主动创造排外文化，无一例外。&lt;/p&gt;

&lt;p&gt;日常生活中也是如此，首先搞清楚你需要多大的蛋糕，然后看看现在你所居住的地方藉由地理学第一定律可以提供多大的蛋糕，再就是衡量下自己能切到多少。盲目跟风的恶性后果一般就是社会上某种总需求的蛋糕并没变化多少，但一旦跟风人多了，不但你本来能拿到的蛋糕少了，付出的代价也更多了。商家是最喜欢营造跟风的氛围的，毕竟多数人善于精打细算自己的小账本，但对全局总是盲目的估计。&lt;/p&gt;

&lt;p&gt;当公交系统成为降低房价的因素时，这个地方的社会隔离就真正开始了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tips for local installation of MetaboAnalyst on Windows</title>
      <link>/en/2017/03/29/metaboanalyst/</link>
      <pubDate>Wed, 29 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/en/2017/03/29/metaboanalyst/</guid>
      <description>&lt;p&gt;I am running Windows 7 to perform metabolomics data analysis(mainly for mscovert). Recently I found MetaboAnalyst could be installed locally. Since some group members really care about their data safety, I just installed MetaboAnalyst on one of group computers. Here is some tips for it:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Windows 7 is currently not supported by Metaboanalyst, so I use virtualbox to install a 64-bit Ubuntu 16.10.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;For Ubuntu, you need to install a few packages to support both the R and Java environment, also some packages. You might follow the script in bash:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install libnetcdf-dev graphviz libxml2-dev libcairo2-dev default-jdk r-base-dev 
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;You also need to install some packages from either CRAN or Bioconductor&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Install Rserver in bash to get rid of configure of R&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get isntall r-cran-rserve
R
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# Use the following code to install packages in R:
install.packages(c(&amp;quot;ellipse&amp;quot;, &amp;quot;scatterplot3d&amp;quot;,&amp;quot;pls&amp;quot;, &amp;quot;caret&amp;quot;, &amp;quot;lattice&amp;quot;, &amp;quot;Cairo&amp;quot;, &amp;quot;randomForest&amp;quot;, &amp;quot;e1071&amp;quot;,&amp;quot;gplots&amp;quot;, &amp;quot;som&amp;quot;, &amp;quot;xtable&amp;quot;, &amp;quot;RColorBrewer&amp;quot;, &amp;quot;pheatmap&amp;quot;, &amp;quot;igraph&amp;quot;, &amp;quot;RJSONIO&amp;quot;, &amp;quot;caTools&amp;quot;, &amp;quot;ROCR&amp;quot;, &amp;quot;pROC&amp;quot;))
source(&amp;quot;https://bioconductor.org/biocLite.R&amp;quot;)
biocLite()
biocLite(c(&amp;quot;xcms&amp;quot;, &amp;quot;impute&amp;quot;, &amp;quot;pcaMethods&amp;quot;, &amp;quot;siggenes&amp;quot;, &amp;quot;globaltest&amp;quot;, &amp;quot;GlobalAncova&amp;quot;, &amp;quot;Rgraphviz&amp;quot;, &amp;quot;KEGGgraph&amp;quot;, &amp;quot;preprocessCore&amp;quot;, &amp;quot;genefilter&amp;quot;, &amp;quot;SSPA&amp;quot;, &amp;quot;sva&amp;quot;))
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;If you want to install Rstudio on 64-bit Ubuntu, you need the following steps:

&lt;ul&gt;
&lt;li&gt;Download &amp;ldquo;libgstreamer plugin&amp;rdquo; from &lt;a href=&#34;https://packages.debian.org/jessie/amd64/libgstreamer-plugins-base0.10-0/download&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Download &amp;ldquo;libgstreamer&amp;rdquo; from &lt;a href=&#34;https://packages.debian.org/jessie/amd64/libgstreamer0.10-0/download&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Install two packages above&lt;/li&gt;
&lt;li&gt;Install the following packages
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;sudo apt-get install libjpeg62
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;MetaboAnalyst is actually a java-based web application (also, R based). You need java environment and use Tomcat or Glassfish to host the *.war file on server (Linux or Mac OS). Then you only need to access it by browser, just like what you did online.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Install Glassfish. I tried Tomcat and the deploy always failed and I suggest to use Glassfish following the guide(you might need to set up user and password) and upload the *.war file by a web interface at &lt;a href=&#34;http://localhost:4848&#34;&gt;http://localhost:4848&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;wget download.java.net/glassfish/4.1.1/release/glassfish-4.1.1.zip
apt-get install unzip
unzip glassfish-4.0.zip -d /opt
cd /opt/glassfish/bin
./asadmin start-domain
./asadmin enable-secure-admin
./asadmin restart-domain
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/war.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Run the Rserve in bash:&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;R CMD Rserve
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;After the installation of MetaboAnalyst on Glassfish, make a port transfer to ensure you could access the MetaboAnalyst on browsers of windows. You need to know the local IP address of both your host and virtual machine(VM).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Your host address is the IP for the connection between host and VM. Use &lt;code&gt;ipconfig /all&lt;/code&gt; to get it
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/hostip.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Your VM address could be found by &lt;code&gt;connection information&lt;/code&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/vmip.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Set up the NAT port transfer to ensure you could access MetaboAnalyst on VM from host browser
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/porttrans.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Save a bookmark for the url(in my case: &lt;a href=&#34;http://192.168.56.1:8080/MetaboAnalyst/&#34;&gt;http://192.168.56.1:8080/MetaboAnalyst/&lt;/a&gt; ) Open the virtualbox all the time at the background
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/ip.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Enjoy local access (while not updated) to MetaboAnalyst&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Every time you restart your computer, input this in bash to start the MetaboAnalyst:&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;R CMD Rserve
cd /opt/glassfish/bin
./asadmin start-domain
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;For the other thing, just follow the official guide &lt;a href=&#34;http://www.metaboanalyst.ca/faces/home.xhtml&#34;&gt;here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>婴儿潮、棉花糖与ABM</title>
      <link>/cn/2017/03/25/abm/</link>
      <pubDate>Sat, 25 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/03/25/abm/</guid>
      <description>

&lt;h2 id=&#34;婴儿潮&#34;&gt;婴儿潮&lt;/h2&gt;

&lt;p&gt;现在国内正在经历的是第四次婴儿潮（第一次在建国后，第二次在三年自然灾害后，第三次在86-91年），一个婴儿潮肯定会导致下一个婴儿潮，这个周期受目前在25-30年左右。同时，经济水平的增长与女性教育水平的提高在一定程度上也稀释了婴儿潮，相信这个周期会不断延长并最终消失。&lt;/p&gt;

&lt;p&gt;我自己属于第三次婴儿潮，成长在一个不怎么缺小伙伴的独生子女政策下，过去的三十年一直都有一种感觉：人多。初中上一届有8个班，到了我们这一届成了12个班，随之而来的是初中高中连续4-5年的疯狂扩招，公立学校分裂出私立学校单独运营，大学则从1999年就开启了扩招的水龙头。然而，当我上大学后就开始听到小学校车频繁出事的新闻，其实这也有婴儿潮的影响。由于学生数量在我们那几届后锐减，很多小学直接开不下去了，特别在农村，原来每个村都有小学，人数减少后只能好几个村合并办学，但上学就成了问题，所以会出现装很多人的不合规的校车，自然也就会有相关新闻。当我读博士时，周边听到就是生孩子建档麻烦，排不上队，很正常，因为又到了我们这一代的生育年龄了。然后就是奶粉代购与母婴用品的高峰期，到现在又闹了一波学区房，想来也是这波人为人父母后懂得预先给孩子争取资源了。如果我是个商人，只要关注我到这个年龄段自己缺什么就去卖什么就可以了，毕竟人多。&lt;/p&gt;

&lt;p&gt;人口，从来都是一个了解世界最重要也最有预测能力的基数。1万人的社区里是发展不出有规模的小众兴趣的，但1000万人的城市你能看到各种规模化的活跃社团。地理上与出生时间上的聚集会衍生出各种前所未有的事件，也不能说前所未有，之前只有苗头，聚集后才会涌现出新事物。而且你会发现在某样兴趣上同样活跃的人年龄也差不多，不在婴儿潮的想活跃起来的时代没有提供足够的人口基数让他遇到有同样兴趣的人。最近几年的用工荒、农村衰落与城市化进程背后也有人口因素，年轻人都进了城自然后代的生活环境更适应城市，而技术含量较低的工作所需要的青年劳动力却在减少。而各种营销概念忽悠的对象也是我这一代人为主，人多购买力大且现在也都有了一定的消费能力。这甚至都不仅仅是经济现象，还造就了文化现象。就连文学影视作品炒的冷饭用的梗也是80、90年代回忆风格的，不是因为这代人的回忆更重要，而仅仅就是因为人多，不仅消费者多，生产者也多，新闻焦点跟着转。很多不同年龄段的人则感受不到这种变化，由此产生的认知与行为偏差很难在代际间传递。&lt;/p&gt;

&lt;p&gt;任何一个组织的年龄分布都隐含了大量的信息，特别是时代背景，正常人思维最容易忽略的就是时代背景。我们可以肆意点评大萧条时代、民国与文革，但总是对自己时代背景隐含的偏见视而不见，这可能是很多悲剧的源泉。这个偏见通过地理位移也不能尽数发现，我也不知道答案，但看新消息时总会有个预设，那就是这背后一定有些偏见与其他的角度，这样去想可以抵御九成以上的概念忽悠。&lt;/p&gt;

&lt;h2 id=&#34;棉花糖&#34;&gt;棉花糖&lt;/h2&gt;

&lt;p&gt;斯坦福大学的棉花糖实验常被用来作为说明自制力对成才的重要性，无数本畅销书以此为案例大谈特谈成功经验与育儿心法。因为我的同龄人大都处于这个阶段，所以最近这个研究在我周围的曝光度也很高，很多父母信誓旦旦说一定要提高自己孩子的自控力。这也是很多人对这类信息的处理方式，抛开论证过程，直击结论并用这个结论指导生活。类似的结论有很多，例如相貌会给事业加分，经济指标与口红、裙摆的关系…这一类的研究结论其实也是一种棉花糖。&lt;/p&gt;

&lt;p&gt;在看科学研究报道时要首先区别开两种研究，一种是调查类研究，另一种是实验类研究。从结论可信度来说后者比前者更可信，但前者是更准确的现状描述。对于调查类研究，有意思的现象是亮点，但因为是调查类研究，通常研究人员并不干涉这个现象。但一定注意的是当结果被报道后，有些现象的根基会被报道所影响产生反馈。例如山东某地的胃癌发病率一直很高，研究人员调查后发现跟当地吃煎饼的习惯有关，因为当地人喜欢吃杂粮煎饼且一次烙好一大摞存放起来慢慢吃，此时在杂粮煎饼中某些杂粮成分并不适合长期保存，容易发酸而刺激胃，进而导致胃癌，经过报道后当地人改变饮食习惯发病率就降下来了。也就是说很多现象会随着反馈消失或加剧，例如如果所有年轻女性都认为外貌会给事业加分，那么美容业与化妆品厂商就会比较高兴且乐于宣传这些，反过来又加剧了这个现象。这个问题在各类畅销书里尤其严重，很多观察与调查类事实被当成不变的规律去论述，后果就是产生了一片佩戴“科学”有色眼镜的求知者，心心念念的都是些社科结论。实验类研究通过良好的设计与数据分析而产生的结论可能更靠谱，但由于存在研究者偏见与p值歧视，这类结论要关注实验过程与数据分析是否合理。我刚读研的前半年每晚打印一篇论文带回宿舍读，初期关注的也是知识性的结论，毕竟我对学科领域不了解，到了后期就更关注结论得出的过程与论证方法了，也正是这个过程让我意识到很多实验性结论的得出是存在问题的，作者跟同行都能看出来，但外界就不一定看得出来了。而且新发表的结论相比学科教科书里的东西更不稳定，在关注时也是需要注意的。虽然我经常对不懂的新研究乱评论，但对于新发现结论本事更多的是观望而不是马上相信。例如关于癌症是坏运气的研究当时感觉是作者玩了一个观察性数据分析的花招，但这两天作者最新的研究则提供了更多的证据，这个过程更符合科学对真相的探索，是持续性改进的。&lt;/p&gt;

&lt;p&gt;很多科学报道或畅销书都在越来越多的使用研究与数据来阐述道理，这点很好，但读者应该也可以用一种科研的态度来对待结论并思考过程。不然这种结论棉花糖会让很多人自认为已经掌握了真相与全貌，而事实上只是一个幻象。最好的方法就是在看到一个结论时去搜相反的意见与评论，这样一个过程不能给你带来确定性，但那又如何，世界本就不是确定的。&lt;/p&gt;

&lt;h2 id=&#34;abm&#34;&gt;ABM&lt;/h2&gt;

&lt;p&gt;ABM，这个是Agent Based Model的简称，是一种研究工具，特别适合动态过程的模拟。现实社会存在一个问题，无论什么样的秘籍，大家都用的话也就不叫秘籍了。这就是反馈过程，做自然科学研究很少遇到这个问题，例如你发现某种鱼的秘密洄游路线也不能把论文给它的天敌看，看也看不懂。但跟人沾边的社会科学研究就不一样了，你哪怕瞎编一个结论都可能对特定人群的认知与行为产生影响，这个影响你用回归分析就搞不定，因为这类行为不回归，完全是反馈反馈再反馈，个体层次看不出规律。但ABM可以模拟这个过程，让你在整体层面上去观察一些现象。举个例子，某城市出现了一个传染病，因为刚出现，你知道的只有一个粗略的感染率与康复率及平均康复时间，此时你打算估算一个整体城市的康复时间（不考虑疫苗），此时就可以用ABM模拟这个动态过程。同理，也可以用在交通灯的设计上。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/abm4.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/abm5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我一直认为在计算相对便宜的今天一味追求数据量来解决问题不如用这些计算资源去模拟复杂场景，你只要搞清楚你会怎么选，然后设计一个空间用不断反馈的动态过程来模拟一群人，最后关注整体指标就可以了。这个过程最需要的知识就是了解个体的行动决策的集合并建模，对于大多数个体行为给一个先验概率赋值并不困难，这样也就很容易对整体建模。模拟这一部分在国内大多数自然科学教材里基本都不怎么讲，但其实这是一个很好的启发式学习方法。例如把污染物迁徙看成一个传播过程，你可以很快用ABM估计出这类污染物在特定污染交互场景里能传播多久，影响多大。现实问题的复杂性并不是几个基本方程可以求解的，此时模拟一个非平衡群体过程可能让你发现之前没有注意到的东西。&lt;/p&gt;

&lt;p&gt;结合年龄分布，理论传播与ABM，你能否探索出一些新东西？又能否付诸实践？应用中的知识才会发挥价值，要学会把实际问题抽象成同构模型。&lt;/p&gt;

&lt;p&gt;君子不器。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>估计、p值与科学决策</title>
      <link>/cn/2017/03/18/estimation/</link>
      <pubDate>Sat, 18 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/03/18/estimation/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;



&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;!-- BLOGDOWN-BODY-BEFORE --&gt;

&lt;!-- /BLOGDOWN-BODY-BEFORE --&gt;

&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;估计&lt;/h2&gt;
&lt;p&gt;科研数据分析中最基本的思维工具就是抽象，也就是把实实在在的事实在保留最大信息量的前提下用最简洁的描述方法展示出来，数学与统计学往往是这类工具的不二之选。估计则是其中最基本的问题，搞清楚其背后的思想才能把工具用的得心应手。&lt;/p&gt;
&lt;p&gt;举个例子，我手头有一堆人的身高，然后找个人（没错，就是你了）让他描述一下这个数据，那么这个人该怎么办？最笨的方法就是把所有这些数读一遍，这种描述不丢失信息，但你读完了我也睡着了。这样传递信息效率太低，那么有没有办法效率高一点呢？&lt;/p&gt;
&lt;p&gt;现在是三月，要学雷锋（这个梗再过几年估计没人看得懂了），背后的思想是什么？榜样。那么一堆数据的榜样是什么？少数服从多数，也就是出现最多的那个数，用这个数做代表就可以了。统计学上管这个数叫做众数，英文mode，加个l就是典型（model），很适合做代表。但是你要是告诉我个众数我就开始犯嘀咕了，是不是也太简化了，假如100个数的众数有10个，另外90个我就直接扔掉，太草率了。&lt;/p&gt;
&lt;p&gt;此时作为科研工作者你应该想有没有更好的表述，至少要把所有数的信息都包括吧。那么我们假想一个数，这个数距离所有N个数的距离最短，那么不就有代表性了。想法有了，如何估计呢？这时我们首先定义这个距离，因为肯定有正有负，就用绝对值的和来表示好了：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(d = \sum_{i=1}^{N}(|\hat x - x_i|)\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;目标是让这个距离绝对值的和最小，最简单就是暴力搜索，产生一个随机数，计算绝对距离和，找到最小的就完活。但当你真怎么做就会发现，最中间那个数或最中间两个数的均值总是最小。此时你脑中要出现一句提醒——是不是有收敛的解析解啊？&lt;/p&gt;
&lt;p&gt;我们把这N个数从大到小排排坐，然后把最大的跟最小的分到一组，次大的跟次小的分成一组，按照我们的距离定义，那个到所有数绝对值和最小的数一定会在这样一组数的中间，那么把这个洋葱壳结构逐层去掉，最中间的那个数就是我们要找的数。统计学上叫做中位数，但其实本质上定义就是这样。也许你会说跟众数比似乎找到这个数直接扔掉了98或99个数，信息保留的不是更少了吗？别忘了我们对信息有一个排序的过程，这个过程本身保留了代表性的信息，虽然看上去中位数没有经过多少计算，其实背后的思想可以看作最小化了一组数跟它距离绝对值的和。&lt;/p&gt;
&lt;p&gt;看到这里可能你会觉得为什么不用均值呢？其实均值模拟的是到所有数距离平方最小的那个数。也就是&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(d = \sum_{i=1}^{N}(\hat x - x_i)^2\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这个距离最小化就不用排序了，牛顿跟莱布尼茨早就告诉你方法了——求导。因为是二次方程，求导得到解析解就是均值，不信你自己算算。&lt;/p&gt;
&lt;p&gt;不论用众数、中位数还是平均值，其背后大致都有个代表性的数学抽象过程，求解需要借助数学工具。同时要注意到其中掩饰很深的东西，那就是虽然数学求解是客观的，但选择使用哪个数或直接读出所有数其实是你来决定的，那种都可以，都有道理，本质上都是信息精简过程中的压缩方法，没有优劣之分，看你对数据的洞察与想解决的问题来定。学知识一定不能学死而是要学活，灵活使用工具讨论科学问题，学术圈自会给出评价。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;p&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;p值&lt;/h2&gt;
&lt;p&gt;关于抽象，另一个案例是p值。关于p值几乎是科研数据分析的周期讨论话题，本来Fisher提出p值根本就没想过有原假使跟备则假设这种设计，而在Neymann-Pearson提出的原假设跟备则假设的体系构架里也没有p值0.05或0.01的设计，但确实是有置信水平跟功效这一说，对应了拒绝域、假阳性、假阴性等一堆概念。也不知道从哪个时候开始就有人把两个理论捏到一起用到科研里去了，但背后的思想非常不同。&lt;/p&gt;
&lt;p&gt;首先，Fisher跟Neymann-Pearson体系解决的是科学决策问题。其实把科学跟决策放到一起是有点矛盾的，科学关注的是事实真相背后有规律性的客观的东西（当然量子力学对这个想法的冲击很大）而决策则比较主观，存在选择过程，但真相如果只有一个（此处应该有柯南主题曲作为背景音乐）应该是没得选啊？那是理论，现实是多数情况你根本就不知道真相，只有一堆假说，但根据事实你可以对假设进行检验。Fisher跟Neymann-Pearson体系为这个过程提供一个很靠谱的推导工具，这也最终让统计学广泛的应用于各个学科。&lt;/p&gt;
&lt;p&gt;具体到Fisher的p值体系，背后的思想是在某假说下这件事发生的概率是多少，例如人群身高是正态分布，那么你看到一个人身高3米，在你假设的人群分布中出现这个身高及以上的概率极低，那么我就有理由认为你看到的不是一个正常人。Fisher这个说法只有单一假设，决策的也是单一假设的可能性。老爷子当年莫名提出了一个0.05的阈值，认为低于这个数假设就不大可能出现，但这个数莫名其妙的成了Neymann-Pearson体系的alpha值。&lt;/p&gt;
&lt;p&gt;好了我们再看下Neymann-Pearson体系，这个体系有两个假说，如果拒绝A就要接受B，同时也定义了假阳性与假阴性，也就是犯错的概率衡量。我们可以得到某个假设下统计量的分布，然后比对的这个统计量是否在拒绝域里，如果在，那么拒绝这个假设，接受备则假设。当然接受原假设但备则假设如果跟原假设统计量设计的比较近时，你就有概率得到假阳性结果，或者说区别不了两个假设。而备则假设如果跟原假设统计量设计的比较远，那么当你拒绝原假设时也有风险得到其实备则为假原假使为真的情况。这就对应的统计学功效分析与错误发现率等多个分支。如果你看到这里看晕了也没什么关系，因为这个体系就是很复杂，Fisher对此也没啥好感，他也不会认可功效分析这种有点拖泥带水的设计。同时，这个体系是频率学派的，也就是多次实验后这个结果应该是稳定的。&lt;/p&gt;
&lt;p&gt;在实际科研的假设检验中是结合了这两个体系的异类，会计算空假设的p值，但用p值来对比Neymann-Pearson体系的alpha值看在不在拒绝域里来决定是否采纳空假设。这个体系被诟病最多的地方在如下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在实际科研实验设计时，实验组与对照本来就应该有区别，而假设检验在这个大环境下发挥的作用有限&lt;/li&gt;
&lt;li&gt;这个体系可以拒绝掉一个假设但不能证明一个假设，且拒绝与接受都存在错误率控制&lt;/li&gt;
&lt;li&gt;重视假阳性而不重视假阴性，科研人员使用时很容易忽视掉功效分析&lt;/li&gt;
&lt;li&gt;置信水平跟p值本质是俩概念，但科研人员使用时经常用词不当&lt;/li&gt;
&lt;li&gt;科研人员对0.05这个阈值有迷之选择偏见&lt;/li&gt;
&lt;li&gt;多重比较问题&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具体就不解释了，但要注意的一点是这些问题的提出者往往是贝叶斯学派的，其替代方案自然也是基于贝叶斯推断的方法：给一个先验分布，用数据计算似然度，然后用贝叶斯公式更新出后验概率。在进行推断时只要对比后验概率与假设条件下的概率的比值就可以了，大于1说明更可能发生，小于1说明更不可能发生。这个推断过程自然不会有错误率的问题，但也会犯错，例如这个比值搞不清出变化方向，也不好衡量与评价变化的数量级，但对于决策似乎更简单明了。当然，我很怀疑会不会被推广，因为贝叶斯推断目前并不在多数学科的统计学教学体系内，虽然论文里经常涉及。同时频率学派跟贝叶斯学派的矛盾是哲学层面的，即便数学形式上是一致，解释起来也完全不同。频率学派总会去质疑贝叶斯学派那个莫名其妙的先验概率，而贝叶斯学派也会去嘲讽频率学派那个多次实验中有几次错误的说法，很多实验就只能做一次，我关心那么多次干嘛？&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;科学决策&lt;/h2&gt;
&lt;p&gt;科研中论断的真假都可以看作一个决策过程，也就是说上面的判断方法都是各学科里默认的方法论。如果结论是拒绝某个假说或接纳某个假说，在具体学科的理论大厦里就可以加入某个定理。但一定不要忘记这是个决策过程，认可是该学科共同体（具体到论文可能就是编辑加几个审稿人）主观接受的，存在大家都错了或都看走眼的可能，也因此不要对很多报道的新鲜研究成果有太多信心，更可能的情况是分工精细的小圈子的群体决策，虽然好过自吹自擂，但也可能只是披着数学统计学还有本学科知识框架的外衣的一个假说或现象阐释，不保真。大众读者在这上面没判断力是正常的，具有数理基础的人不要被轻易忽悠，存疑是科研的美德。&lt;/p&gt;
&lt;p&gt;除了基于事实与实验的科学决策，也存在其他的决策方式，例如直觉决策，逻辑推理决策等。从最终效果上看，并不存在某种决策方法能在所有场景下都玩得转。而且，在做出某项决策后，其判断会不断反馈影响到后续的决策过程。如果一个人觉得一直都判断准确，很有可能多个判断间存在相关与反馈而不说明这个判断在真实意义上的正确。其实可以尝试这样的思想实验，你如果做了另一个判断，是否也会出现类似的正反馈。这样去想很多事或规律在历史上的正确只能称作经验事实正确，基于经验事实提取的规律可以保稳，但能产生变数的决策是要具有前瞻性的，或者说如果某件事处于僵局，经验不起作用而动态反馈的决策方法更可能有效改变僵局。举个例子，如果乔布斯不做触屏手机，那么现在大家用的大概率还是智能键盘机，而在是否用触屏的问题上当时并无太多经验可以借鉴。虽然现在手机触屏成了标配与主流，但其产生时的决策依然是高风险的甚至是任性的，当然历史你没得假设。&lt;/p&gt;
&lt;p&gt;现在热炒的大数据很大程度上依赖于挖掘现有的行为规律然后定向营销，一个可预期的后果就是商家的销售行为会让潜在的规律变的明显，让消费者回归到他可能隶属于的消费类型，这无疑会加剧社会的割裂。举个例子，我在某个引入人工智能的推荐系统里很偶然的对一个其实喜欢的书点了一个不喜欢，后果就是基于个性化的推荐算法再也不会给我推荐这个类型的书。假设我买书是个低频行为且只依赖大的网络电商，那么某个偶然的行为就可以完全让某个类型的书彻底退出我的视野，就好像从来没存在过一样。基于此，我倒有点想念不那么智能甚至低效的推荐系统，起码它会给我我不想要的，而看书这件事，我并不在意看到不同意见，反倒是全是熟悉的意见会让我自大且固步自封，但却对商家有益。说到底还是需要公益的非盈利的人工智能的推荐系统，我可不想总是遇见熟悉的环境而被隔离开。同理，决策上也最忌讳一意孤行，起码在科研数据分析中，要抽象的去理解不同决策过程背后的东西，方法的背后有艺术。&lt;/p&gt;
&lt;p&gt;Science is more than a body of knowledge; it is a way of thinking. … The method of science, as stodgy and grumpy as it may seem, is far more important than the findings of science.&lt;/p&gt;
&lt;p&gt;— Carl Sagan&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>回归、安慰剂与流行</title>
      <link>/cn/2017/03/12/regression/</link>
      <pubDate>Sun, 12 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/03/12/regression/</guid>
      <description>

&lt;h2 id=&#34;回归&#34;&gt;回归&lt;/h2&gt;

&lt;p&gt;在科研数据分析中，回归分析的使用频率可能仅次于假设检验。我们现在提回归分析更多是说数据回归到我们预设的自变量因变量模型的分析，例如线性回归就是说假设了自变量与因变量之间的关系是线性的，那么通过拟合这个模型得到一堆自变量系数，然后通过一堆关于系数（t检验）或模型本身（F检验）的假设检验来说明模型对数据的解释能力。但其实回到100多年前其诞生的维多利亚时代，回归这个说法更多的是特指“回归到均值”，而这背后的故事其实也很有启发性。&lt;/p&gt;

&lt;p&gt;回归这个说法诞生于高尔顿关于种子的研究，但真正出名却是在1886年关于父母与子女身高的遗传学&lt;a href=&#34;http://galton.org/essays/1880-1889/galton-1886-jaigi-regression-stature.pdf&#34;&gt;研究&lt;/a&gt;之中。高尔顿发现子女的身高要比父母的身高更趋向于平均身高，反之也成立。那个时候多数人已经知道的是父母的身高会影响子女的身高，但“回归到均值”的思想说的却是除了遗传因素，冥冥中还存在一种向均值回归的力量。两个都很高的父母的孩子身高会高，但总没有父母那么高；同样两个都很矮的父母的孩子身高也许会矮，但总没有父母那么矮。前面这句话里父母跟子女互相替代也成立，总之就是所有人的身高都趋向于整体的均值。&lt;/p&gt;

&lt;p&gt;这个思想其实跟科研中常说的相关性研究是互补的，科研关心的是有关系的变量，但回归到均值的思想说的却是如果没有关系，两组变量都会收缩到均值。也就是说，也有一个客观的变化趋势。这是基于观察的规律，但其实很有指导价值。&lt;/p&gt;

&lt;h2 id=&#34;安慰剂&#34;&gt;安慰剂&lt;/h2&gt;

&lt;p&gt;在医药研究中经常会使用安慰剂来观察某种药是否真的有效，但如果你考虑回归到均值的思想就会发现一个事实：安慰剂效应可能是天然存在的，也就是不论你试验什么新药，那个没啥效果的安慰剂总会显示出效果。&lt;/p&gt;

&lt;p&gt;下面我用一组1000人的模拟数据来说明这个问题。首先我们不去管新药，就去考虑那一组吃安慰剂的。假设我们监测了人群中某项指标例如血糖并认为其是均值100，方差10的正态分布，那么吃过糖丸之后其血糖应该跟之前差不多。这个就类似父母身高与子女身高。我们默认前后变化大概符合&lt;/p&gt;

&lt;p&gt;$$y = 0.9x+error$$&lt;/p&gt;

&lt;p&gt;这个error我们假定为均值10，方差10的正态分布噪音，也就是说对于一个人群，吃安慰剂前后血糖变化应该是长这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/galton1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;同时我们认为高于110的人是高血糖，也就是新药与安慰剂实际只会在存在高血糖的人中使用，也就是这一部分：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/galton2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;这样我们会看到无论是否治疗，总有下图的部分患者自然恢复了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/galton3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;那么这部分算不算安慰剂效应呢？自然是不应该算，因为安慰剂效应是要基于病人的期望的，而真实的情况却是因为存在“回归到均值”的现象，哪怕病人不想康复或不相信治疗，他还是有可能好转的。由于药物试验一般都会去选择人群中的病人进行双盲对照试验，那么可以预期的是安慰剂效应被天然高估了。同理，药物治疗过程中的药效也会因为存在向均值回归的现象而被天然高估。用一个更常见的中西医争论来说就是不论中西医是否真的有效，对于有些疾病，本来就会自然而然痊愈，如果这个比例本来就很高，那么很多治疗手段根本就是多余。&lt;/p&gt;

&lt;p&gt;没错，确实有个领域是这样的，那就是营养学。各种保健品跟所谓“养生”手段其实就在长期系统性玩弄这个手段，有时候会有人争论哪怕安慰剂效应也是有用的，但很不幸的是这个所谓的“有效”可能根本就是“向均值回归”的一个外在表现，跟心理作用也没啥关系。所谓买个心安理得其实也是交智商税了，起码有一定数理统计基础的人不应该去凑这个热闹，倒不是怕花钱，实在丢不起那个人。&lt;/p&gt;

&lt;p&gt;这个思想可以类推到所谓“生活方式”的领域，兜售各种“健康”、“流行”还有“品位”概念并觊觎你钱包的人，离得越远越好。&lt;/p&gt;

&lt;h2 id=&#34;流行&#34;&gt;流行&lt;/h2&gt;

&lt;p&gt;说到流行，其实是很有意思的自发现象，可以理解成系统性的均值偏离。人总是倾向于新鲜的事物，一成不变的东西总会视而不见而认为恒常。其实都在变，你重复去看一段笑话，看多了也就不那么可乐了，你会说我笑点变高了，其实是你均值偏移了，不断偏移你就很难乐起来了，大家都吃肉，肉就不好吃了。这种均值偏移有时是瞬时的，举个例子，在音乐厅听完一段演奏，大家鼓掌致敬，这时有人觉得特别好就站起来鼓掌，如果大家都互不干扰可能就完了，但如果又有人站起来呢？如果在音乐厅里的人群能让他们起立的人数分布为&lt;/p&gt;

&lt;p&gt;1，1，2，3，4，5，5，5，5，5，5，5，5，5，5，5&lt;/p&gt;

&lt;p&gt;那么没人会起立，因为没有人可以达到自己起立的阈值，但如果此时有一个人恰巧站起来打算上厕所而不是鼓掌，最后几乎所有人都会站起来鼓掌，因为虽然有的人需要另外5个人起立才能站起来，但由于存在不间断的上升阶梯，一个随机扰动就可以让所有人起立鼓掌。如此反复，其实你的品味会不断去贴合整体观众的品味，进而形成一种圈内氛围，大家的喜好变得相对一致，你也就实现了均值回归。有意思的是，你如果需要更多人认可的数目越少，越有可能成为整体同化的关键因素。换句话讲，如果你打算说服一群人，最好找个摇摆不定或者总持怀疑观点的人下手，他们都搞定了，其余的随大流就不难了。同样的，如果你去看亲戚朋友表演的晚会并想捧场，尽量坐前排，这样当你站起来鼓掌时几乎所有人都看得到，也就更容易动摇到摇摆的人。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>美人税、人工智能与知识经济</title>
      <link>/cn/2017/03/05/beauty-tax/</link>
      <pubDate>Sun, 05 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/03/05/beauty-tax/</guid>
      <description>

&lt;h2 id=&#34;美人税&#34;&gt;美人税&lt;/h2&gt;

&lt;p&gt;《世界奇妙物语2016春季特别篇》里讲述了一个关于美人税的故事，女主人公爱子是个美女，因此在职场上处处春风得意，然而政府认为这样有碍竞争公平就针对性地征收了美人税。女主在经历了开始的不适应后逐渐接纳这种税作为一种身份认可，然而，在同为美女的母亲去世后自己不但拿不到遗产还要补交税款，这使得女主不堪忍受并通过装丑来降低税率，女主这一行为被以偷税漏税的罪名起诉而入狱。监狱里女主最终认识到心灵美才是重要的，但出狱后意外发现自己不用交税了，这时女主才注意到政府认为美人税交的人太少而改变了美丑标准来增大收税人群，而女主此时已经成为社会意义上的“丑女”了。&lt;/p&gt;

&lt;p&gt;这个故事其实也是有研究基础的，外观是会实打实地给条件一致的人创造更多的工作机会。而澳大利亚两位经济学家&lt;a href=&#34;Unpacking the Beauty Premium: What Channels Does it Operate Through, and Has it Changed Over Time?&#34;&gt;考察&lt;/a&gt;了1984年到2009年间澳大利亚人口中外貌的影响后发现，更漂亮的人不仅仅职场上会受益，整个家庭收入也会提高。同时他们也发现在这25年间，这个影响几乎是稳定的。如果澳大利亚的结果可以推广的话，我们就能知道一个现实：类似外貌的天赋对于个人的事业家庭发展是有助益的。贫富差距过大会导致社会失衡，一个很自然的想法就是我对他们收税就可以了。但我想强调的是第二个研究结论，那就是这个影响会不会继续稳定下去，如果不稳定那么也没有太大的必要进行外部干扰。&lt;/p&gt;

&lt;h2 id=&#34;人工智能&#34;&gt;人工智能&lt;/h2&gt;

&lt;p&gt;最可能对外貌优势产生影响的其实就是人工智能。很多人担心人工智能产生意识取代人类，这个我不做评价，但眼下看得到的却是人工智能会影响定价策略。说白了，如果你经常在网上活动，那么你看到的价格将受你网上行为记录的影响，天天看宝马奔驰的人买机票价格就基本没啥折扣而天天搜青旅的人则可以看到更低的折扣。也许你说我新注册一个用户或者清除缓存不就完了，也许5年前可以这么做，现在已经没用了。&lt;/p&gt;

&lt;p&gt;只要你是一个互联网重度用户，你的设备、经常登录的IP所代表的地点、常用邮箱或ID、打字习惯、浏览习惯等都可以用来追踪到你而且目前就有这样的公司，号称掌握千万甚至亿级用户的唯一标志符，其服务对象多半是互联网电商，当然也有非营利机构。只要你在产生互联数据，就会有算法对你进行画像与归类，然后就是定向营销。这个所谓个性化的服务其实本质上都是在发掘现金奶牛，调动并满足你的需求。看起来像是双赢，你很快找到自己想要的东西而商家很快找到顾客，但实际上很快你就会有爱子的感觉，那就是钱越花越多而收获到的东西大概是所谓的潮流吧。&lt;/p&gt;

&lt;p&gt;更尴尬的是你根本就不可能逃离这个循环，当你缺钱时，然后你的互联网记录会告诉算法，这个人没现金了，而算法也会通知银行，这个人快破产了，风险角度不要借钱（银行不大可能不买），然后它可以推点p2p或高息信贷了，相信你还是会觉得这个算法很贴心的。等到这个人真正已经破产，就会成为算法忽略的那一部分“互联网流浪汉”，此时互联网已经不打算让你互联接受“免费”且“贴心”的服务了。&lt;/p&gt;

&lt;p&gt;相比所谓人工智能控制人类，市场借助人工智能控制人类更可怕也更具有可行性，因为这个实打实会创造利润且被各大互联网寡头追逐。所谓的电商、金融、政府如果都进行充分的信息流通，那么一个可预计的后果就是过往构建算法的经验知识将成为真正统治互联网的规则。那些社会上不可明说的规矩例如有房才结婚、女性要持家、喝红酒有品味、练毛笔字有文化…都会被算法捕捉用来训练自己的模式。基于经验构建的算法不会考虑反馈，但反馈的效果却会用来继续强化算法，这样的商业市场社会不知道会有多少人喜欢，但目前正在形成。天赋也好、努力也罢，很多原来根本不会有人去思考的行为模式只要形成规模产生效益就可能被人工智能放大并用来牟利，此时旧有的基于非互联网模式产生的道德与伦理都可能变得不再稳定。&lt;/p&gt;

&lt;h2 id=&#34;知识经济&#34;&gt;知识经济&lt;/h2&gt;

&lt;p&gt;知识经济是伪的，是少数人圈钱自嗨忽悠出来的概念，而这两年教人成功的人比真正成功的人还多，他们传播着各种“消费升级”的理念，其本质就是前面所说的那个算法，把经验固化成教条。但其实知识这东西从来都不是听着摘要与结论就能掌握的，因为这些人很少让你自己去思考问题而是通过论文、权威著作与亲身经历生生把一些东西压给读者，而且还收费。给我感觉像是另一种包装过的人生应试教育，而且还通过收费来强调“花了钱才会学”，这招你在健身房没见过？&lt;/p&gt;

&lt;p&gt;数据都是很诚实的，你去看看那些订阅过的专栏，再看看里面的文章阅读数你就知道大概有多少人只是通过购买这种仪式感来忽悠自己了。一年以后，也许会有各种优惠让你继续这种仪式感，反正赚钱的又不是你，你只是付费工具。真正学到知识可能只有通过不断思考这一条路径，如果在这个知识经济喧嚣的时候你从中体会了乐趣那付费是合适的，如果没有，最好别让这些卖人生经验的去持续干扰你构建自己的人生经验，毕竟这只是风潮，过后冷静下来你还是得学会面对你是你，他是他的现实。&lt;/p&gt;

&lt;p&gt;知识经济的伪就伪在这本质上还是一种营销，引导你的愿望并告诉你这玩意有用有意思，通过你的消费来告诉你你的选择是对的并不断加强，然后等你发觉这是虚幻时它又去忽悠下一批了。有用也好、有意思也罢，都应该你自己说了算，而不是大v跟人工智能算法说了算。好比被收了美人税的爱子感到的身份认同，现实中不知道有多少人沉浸其中，殊不知美丑规则都是可以被摆布的。&lt;/p&gt;

&lt;p&gt;我不是在写科幻。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>二十年博士延期之怪现状</title>
      <link>/cn/2017/02/19/phd-extend/</link>
      <pubDate>Sun, 19 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/02/19/phd-extend/</guid>
      <description>

&lt;p&gt;坊间有句话叫做“没有延期毕业的硕士，没有按期毕业的博士”，最近放长周末假，就抓了点数据探索了一下这个问题。（来自教育部网站公开数据&lt;a href=&#34;http://www.moe.edu.cn/s78/A03/moe_560/jytjsj_2015/）&#34;&gt;http://www.moe.edu.cn/s78/A03/moe_560/jytjsj_2015/）&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;研究生教育现状&#34;&gt;研究生教育现状&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/admitted.png&#34; alt=&#34;&#34; /&gt;
这是最近20年研究生招生情况，可以看出硕士的扩招力度是远高于博士的，但两者都在扩，20年前一共6万多，现在仅博士每年录取就有7万多，硕士则扩张了10倍有余。
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/graduates.png&#34; alt=&#34;&#34; /&gt;
这个则是研究生毕业状况，伴随扩招，每年招生人数与毕业人数有相当的差距，但比较吊诡的是博士招生在增长而毕业人数却趋稳了，这基本暗示延期的常态化。
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/enrolment.png&#34; alt=&#34;&#34; /&gt;
通过在读人数我们也会发现，研究生这个临时身份群体在不断扩大，除了扩招影响，另一个自然就是前面提到的延期问题。&lt;/p&gt;

&lt;h2 id=&#34;延期现状&#34;&gt;延期现状&lt;/h2&gt;

&lt;p&gt;自从2003年起，教育部增加了下年预期毕业人数的数据，这样根据真实毕业人数，我们可以计算出当年延期的状况：
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/extend.png&#34; alt=&#34;&#34; /&gt;
图上我们可以看出，基本上博士延期概率超过50%，硕士延期概率是个位数，也就是说“没有延期毕业的硕士，没有按期毕业的博士”这句话没毛病，而且延期超过50%的时间已经超过10年了。同时另一个现象也值得关注，那就是女性研究生的延期概率是普遍低于平均水平的，那么对应的男性研究生延期概率会更加惨不忍睹。&lt;/p&gt;

&lt;h2 id=&#34;延期会延多少年&#34;&gt;延期会延多少年？&lt;/h2&gt;

&lt;p&gt;上个问题我们可以看到延期情况是客观存在的，那么延多久就是另一个问题了。如果我们用在校生去除当年毕业生，会得到下面的恐怖结果：
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/meangrad.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;也就是说，博士需要6年多毕业而硕士也需要3年多毕业，硕士那个考虑到延期概率不高还可以接受，博士那个就有点反人类了，而且从近几年情况看这个毕业年限还在增加。其实答案很简单，就是扩招导致的人口在高校或研究机构的滞留，那么如何去除这个影响呢？考虑到博士硕士其实应该是2-4年内毕业，我们只要用当年录取的人数去对比2-4年后毕业的人数就可以了。结果如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/year2.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/year3.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/year4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;考虑到博士毕业率应该低于硕士且硕士毕业率不应该超过100%，应该是3年毕业的数据比较可信，但同时我们会注意到3年毕业率要远高于延期概率，这又是怎么回事？&lt;/p&gt;

&lt;p&gt;这里就没数据支持了，但我想大多数研究生都听过硕博连读这个概念，其实如果三年毕业为真，那么硕博加起来应该是6年，而硕博连读应该是5年，如果博士延期是常态化的，那么我想这里面很大一部分比例是硕博连读。估计再过几年，考博的比率可能会更低而硕博6年将成为默认的学习年限。有打算硕士毕业出国读博的可以考虑下了，年限上其实吃亏不多而且国外会有老板没钱了逼着早点毕业的情况。&lt;/p&gt;

&lt;h2 id=&#34;国内教职状况&#34;&gt;国内教职状况&lt;/h2&gt;

&lt;p&gt;刚才说了研究生毕业的供给端，下面看看需求端也就是教职的变化。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/positionall.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;国内教职因为99年开始的扩招导致在21世纪的第一个5年大量的扩展教职，这样的后果就是有一个5年的教职年龄高峰，这个高峰占据了大量的教职。从图上看，目前这个高峰年龄段在51-55岁，都算是当打之年，如果退休年龄没有明显推迟的话，那么在10-15年后应该可以看到一个因为退休高峰导致的教职空缺期。那么10到15年后谁博士毕业呢？大概是现在读中学的孩子，反正我老人家是赶不上了。其实考虑硕博6年加本科4年，每个高校都有义务在学生刚接触高等教育或研究时给他们领先当前技术10年的教材与方法，否则学生10年前选了小灵通网络优化专业，博士毕业基本就只有转行了。&lt;/p&gt;

&lt;p&gt;那么女性教职呢？&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/positionallf.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我只能说似乎女性教职前期扩张的要更厉害，平均年龄也更低，大概要20年左右才能迎来退休高峰的教职空缺，如果校方固定当前男女比，那么其实对有更低概率延期的女性并没有什么优势。此外，我们来看下教职中教授的年龄分布状况：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/positionprof.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出教授平均年龄会大一点，当前教授主流是51-55岁，反推下基本是刚改革开放后上的大学，经历应该挺丰富的。我们再看下副教授的情况：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/positionprofa.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;可以看出副教授整体要比教授年轻10岁，大概90年前后上大学，46-50岁这个年龄段人数基本稳定，说明升教授基本就是前一个年龄段，从年龄分布上看35-45岁人多，不同代际间竞争会激烈些。&lt;/p&gt;

&lt;h2 id=&#34;年教职数变化趋势&#34;&gt;年教职数变化趋势&lt;/h2&gt;

&lt;p&gt;前面着重强调年龄分布可能带来的教职空缺，另一种空缺就是所谓扩张期或窗口期，我们看下这个趋势，当然这个数没考虑退休，但从年龄分布上看这一部分的人数似乎比较稳定。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/positiontrend.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从教职数上我们可以看到，每年的教职数一直在提高，而是似乎斜率比较稳定。但是女性的教职数增长的回归斜率只有总数的1/3，也就是说每增长3个教职才会有一个是女性的，这说明教职市场存在一定的歧视。但这个问题不好直接下结论，因为辛普森悖论也是同样的语境。同时，教授与副教授教职增长的斜率低于总体，暗示了教职里存在的层级结构。&lt;/p&gt;

&lt;p&gt;总之，目前还算是一个稳定的窗口期，教职数不断增长，属于利好；但成长空间不算大，别忘了博士毕业生可是年年增长，所以以后熬年限是肯定不行的，31-35岁的副教授人数逐年下降，不是升迁（概率低）就是收紧了要求转而直接从海外引进人才，诸君努力吧。&lt;/p&gt;

&lt;h2 id=&#34;教职与博士毕业生供求&#34;&gt;教职与博士毕业生供求&lt;/h2&gt;

&lt;p&gt;首先，我们都知道研究生学历在贬值，那么究竟贬到什么状况了呢？我计算了同年毕业的博士与硕士人数比例，结果如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/phdvalue.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;很明显，硕士的贬值效果更强，博士相比之下反而在升值，女博士升值更高。当然，大前提是五十步笑百步，你懂的。基本的情况就是1个博士大概对应10个硕士，显然硕士作为一个学位扩的有点太猛了。后面的分析就不考虑硕士找教职了，基本没戏。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/positionphd.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;通过这个图（我赌一瓶胡椒博士教育部2000年的数据绝对有问题）我们可以看到新增教职数这些年基本稳定在2万这个水平，博士毕业生大概超过5万，也就是说教职市场在今后可预期的时间里撑死也就能解决一半博士的就业，另外有一半肯定会转行。考虑到博士学位对硕士学位是升值的，估计非教职市场上应该挺容易就业的，当然看你干不干了。&lt;/p&gt;

&lt;p&gt;我们进一步看一下女性教职，如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/positionphdf.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;很遗憾新教职里女性比例是低于人口比例的，但这二十年却一直在增长，同样在增长的则是博士毕业生中女性的比例，伴随这个趋势，教职里对女性的歧视似乎是要好于社会其他行业的。&lt;/p&gt;

&lt;h2 id=&#34;小结&#34;&gt;小结&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;没有延期毕业的硕士，没有按期毕业的博士&lt;/li&gt;
&lt;li&gt;从上大学到博士毕业大概要准备10年人生最好的时光&lt;/li&gt;
&lt;li&gt;然后就进入了发展空间可预期的教职市场（掌握通过年龄分布推测的技巧）&lt;/li&gt;
&lt;li&gt;或者转行到业界，学历贬值速度低于硕士&lt;/li&gt;
&lt;li&gt;女性在博士延期可能性上低于男性，但在教职市场上存在歧视&lt;/li&gt;
&lt;li&gt;没有分专业讨论，我大体看了下数据，理工科延期概率显著高于其他专业，约70%-80%的延期率，医学最低（但他们本来年限就长）&lt;/li&gt;
&lt;li&gt;教育部应该给api的，网页数据格式乱七八糟，洗数据洗的我上火&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>读博士是否一定要做学术？</title>
      <link>/cn/2017/02/04/fermi-estimate/</link>
      <pubDate>Sat, 04 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/02/04/fermi-estimate/</guid>
      <description>&lt;p&gt;2015年全国博士毕业生5.4万人，而去年大概到了6万人，按照很多人的说法，读到博士就应该去做学术，但我对这个问题做了一个费米估计，结果比较有意思，列出来供各位打算做学术的博士参考。&lt;/p&gt;

&lt;p&gt;如果成为院士（中国科学院／中国工程院）算学术巅峰的话，那么院士的选拔可以看作到达顶峰的路径。选拔方法是什么呢？两年一次，一次总共大概150人，工程科学对半分，平均一年75人。&lt;/p&gt;

&lt;p&gt;我们假定若干年后每年还是75人，因为两院院士总规模这么些年并未有很大规模的变化，就算加上文科一级教授也就是100这个数量级。&lt;/p&gt;

&lt;p&gt;那么若干年后竞争这个数的人选平均看大概都是同年级的博士同学。目前每年全国土鳖博士毕业生6万多人，算上海归，同一年龄组大概7万人应该比较合理。&lt;/p&gt;

&lt;p&gt;那么你看到了，你需要在同年级博士毕业生里成为千分之一左右的精英才算有希望成为院士级别的学者。这个似乎有点丧气，可能院士这个比较难搞，那么准院士的杰青呢？全国每年选拔200人为杰青，那么成功概率乐观估计是千分之三，杰青其实也很难了，我们再放宽到优青。全国每年选拔400人为优青，那么乐观估计成功几率大概是千分之五。即使我们大胆认为博士有一半不从事科研工作，几率翻倍成为优青也要是百里挑一。&lt;/p&gt;

&lt;p&gt;也许你会说优青杰青比较遥远，那么教授或者正高不算遥远了吧，毕竟每个博士背后都有一个博导。那么全国博导能有多少呢，乐观估计6万，年龄分布从35岁到65岁，如果是均匀分布的话且保证65岁退休，那么每年能产生出2千正高岗位，除以当年大约7万的博士人数，这个比例不到百分之三。就算我把那些做学术但不培养博士的岗位算上，这个比例也不会超过5%。硕士毕业生15年大概50万，说明副高大概最多也就这个数，每年也就1-2万岗位，也就是说大概20%的博士最终能走到副高，其实这个比例也不算高，不过可以作为大多数人可以预想的目标。&lt;/p&gt;

&lt;p&gt;你可能会说做学术要有一定理想，不能这么功利，说这话的有相当比例站着说话不腰疼。如果你已经走到教授研究员这个档次自然可以跟人谈理想，但坦白说现在的博导平均拿到学位都是20年前的事了，那个时候博士一年毕业7千多人，而现在博士毕业生数目翻了10倍，换句话在目前的晋升条件下你成为教授的概率大概是50%，如果有一半不做学术，几乎可以肯定就是教授了。10年前一年博士毕业人数大概是现在的一半多，这意味着其晋升教授可能性也有十分之一，尚算合理。但10年后如果博士年毕业生达到10万，那么其成为教授将跟现在成为优青差不多难度，代际不平衡是十分严重的。不了解基础状况就把人往坑里带的后果挺严重的，自上而下，金字塔顶端人数就那么多，一味扩大底端几乎意味着大量博士要陷入无尽的博后循环之中去拉伸等级。&lt;/p&gt;

&lt;p&gt;所以其实我挺理解很多劝博士毕业转行的看法的，那怕你手握博士学位，目前在国内想走到教授也是个p&amp;lt;0.05的事，大概20个人里有一个。考虑到一般博士同学同院系大概也就是20个人，如果学术水平不在前面，基本可以重新考虑下人生规划了，因为此时你选择科研就真的需要兴趣激发了，不然身边的落差会折磨你几十年。而且上面的估计有个严重的问题，那就是大量使用了均匀分布，但真实的情况却是极不均匀分布，你的师承关系跟毕业院校都会把这个分布搞得更加极端，而且后发者优势在科研里面非常常见，但前面的坑都满了你怎么让后发者上？&lt;/p&gt;

&lt;p&gt;同时要注意，国内博士毕业生人数还在不断上升，一方面说明教职还是有空间的，另一方面则暗示了今后博士毕业生生存环境将会更加恶劣，竞争会更加激烈。同时，目前教职数目会逐渐趋稳，如果你没赶上新学科新方向的窗口期大爆发，基本就是始终要接纳这个竞争强度了，只会更强不会更弱。而且有些研究方向必然因为学科发展走向没落，没必要跟一伙老气横秋的人抱团取暖，该转方向就转，反正大家都没基础。&lt;/p&gt;

&lt;p&gt;读博转行可能也是个好事，早点把青春奉献到知识洼地去才更能实现自己的价值，相比学术界科研，业界科研可能是一个很好的选择，毕竟能磕下博士学位，搞点别的也应该没啥问题。&lt;/p&gt;

&lt;p&gt;同时，如果选择了科研道路也要知道上面的概率，当不成分子也可以先做分母，心态上说服自己静下心来做科研就OK了，乐在其中则何乐不为？切不可惶惶不可终日，空费时光。&lt;/p&gt;

&lt;p&gt;数据参考：&lt;a href=&#34;http://www.moe.edu.cn/s78/A03/moe_560/jytjsj_2015/&#34;&gt;http://www.moe.edu.cn/s78/A03/moe_560/jytjsj_2015/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>现代科研人员的日常</title>
      <link>/cn/2017/01/27/modern-scientist-weapon/</link>
      <pubDate>Fri, 27 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/01/27/modern-scientist-weapon/</guid>
      <description>&lt;p&gt;8:00AM-9:00AM&lt;/p&gt;

&lt;p&gt;起床，吃早饭并准备午饭离开寓所。在公交上打开手机上rss阅读器，扫一眼生活文件夹看看有什么新闻或关注的博客，资讯一扫而过，长文发送到pocket里晚上处理。那个标注文献的文件夹是每周五下午组会后才需要清空已读的，虽然未读数字已经跳到100+了。一般而言，scinece、nature跟pnas上很少有本专业的论文，有的话也可以从别的渠道看到，rss会追踪本学科内top3的期刊跟自己研究方向的关键词，100%的论文会看题目与图形摘要，20-50%的论文会读摘要，5-10%的论文会读里面的图片，1-3%的论文读全文。&lt;/p&gt;

&lt;p&gt;9:00AM-9:30AM&lt;/p&gt;

&lt;p&gt;到达实验室，跟博后博士生硕士生打个招呼，然后打开内部交流用的slack，看到教授昨晚又分配了一个任务，分享了5篇刚发表的论文，三篇hashtag是ideas，两篇hashtag是experimental design，另外今天要跟一个博士生讨论课题A的进展，还要给另一个新进组的硕士生做内部培训，好在之前的资料都在课题组dropbox的共享文件夹里放着，先发给她吧，反正她也不会看。找到自己的channel，查了下今天要完成一个审稿，还要按照上次跟教授单独讨论（两周一次）的内容改下一篇初稿，另外下午要去准备后天实验的一些标准品。&lt;/p&gt;

&lt;p&gt;9:30AM-11:00AM&lt;/p&gt;

&lt;p&gt;审稿，老实说这篇论文新意不错，但数据处理上很诡异，画的曲线也没有解释，不知道拿什么拟合的，另外这电镜图太模糊了，补充下实验也好。作者用figshare分享了原始数据，写了个脚本跑了下，发现结果跟文章中一致，这点倒不错。平均审稿时间大概是6小时，1.5小时读明白，3小时检查细节，1.5小时写审稿意见，当然一般会分散到5天里去完成，所有意见都标注到了一个对应的google docs上防止忘记。审稿要么就快，要么就不审，将心比心。需要注意的是审稿记录一定要用Publons保存好，因为这也是积累学术声誉的一个重要途径。最近比较流行的Pubmed Commons也可以关注下，发表后审稿或评论将会是学术交流的新趋势。&lt;/p&gt;

&lt;p&gt;11:00AM-12:00PM&lt;/p&gt;

&lt;p&gt;对硕士生进行内部培训，内容包括介绍实验室内部交流软件slack的使用方法与资源获取、对外报告统一的演讲风格与logo、数据分析的模型使用偏好与原因、财务流程……因为之前有积累的培训资料，要求学生一周内掌握好“实验室语言”并会在下次组会安排一个自己背景介绍的报告作为验收。现在的实验室人员流动性大，重复培训有时会消耗大量精力，要逐渐收集留档之前培训或workshop的内容作为自学资料并设置验收，都是成年人了，没必要求着学，自学更新去吧。新人的培训是很重要的，但学校研究所都一直会有面上的培训邮件，实时转发就可以了，如果他不是打算混学位应该知道该怎么做。&lt;/p&gt;

&lt;p&gt;此外，新手科研人员要重视个人在线学术档案的管理，可以在researchgate或academia上注册并更新自己的学术档案并参与社区问答构建在线声誉，谷歌学术或百度学术的档案也要注意维护，因为它们的搜索优先级高。&lt;/p&gt;

&lt;p&gt;12:00PM-1:30PM&lt;/p&gt;

&lt;p&gt;午饭，饭后查阅邮箱，发现有人询问之前发表文章的数据处理细节，找到当时项目的github repo直接发过去，这些都会在发表后公开。另外发现自己researchgate关注的几个课题组也发表了新文章，当然很多跟教授早上发的比较重叠，也有些追踪的项目更新，biorxiv上关注的大牛也出了新的预印本论文。大概看看，在twitter上转发下有意思的论文。此时算作午休，不用研读，只要记录。另外回复邮件时尽量简短，不用太多客套话，要知道邮件正在逐渐被微信等新兴交流方式替代，关注你关注的问题。邮件里提到的待办事项直接记录到在线日历里设置提醒，然后就不要想了。&lt;/p&gt;

&lt;p&gt;1:30PM-2:30PM&lt;/p&gt;

&lt;p&gt;跟博士生讨论下在研课题的结果，总体结果不错，但需要补充几个实验。这个过程不是面对面的，因为这个博士生正在另一所高校访问，交流是通过谷歌环聊（国内可以用微信）与谷歌文档（国内可以用石墨）协作完成的，一边讨论一边修改协作文档里的报告，借助语音输入，讨论完了基本报告也成型了，共享给教授并在slack上项目channel里进行了记录。&lt;/p&gt;

&lt;p&gt;2:30PM-3:30PM&lt;/p&gt;

&lt;p&gt;论文修改，使用rstudio里rmarkdown进行论文写作，通过rticles包里的模版可以直接生成tex文档跟pdf。文献管理使用zotero，毕竟在线收集比较方便。习惯所见即所得的可以用谷歌文档配合paperpile，当然word跟endnote的组合也可以，看个人习惯。文献库要每周更新，按项目分组，这样可以提高效率。论文成稿后可以酌情放到预印本服务器上，这样可以一定程度避免出现审稿过程中的抢发。&lt;/p&gt;

&lt;p&gt;3:30PM-5:30PM&lt;/p&gt;

&lt;p&gt;准备后天实验，这是体力活，也是每天耗时间最多的，因为总有意外。不要把一天分给一件事，要把一小时分给一件事，专注处理一件事。&lt;/p&gt;

&lt;p&gt;5:30PM-6:30PM&lt;/p&gt;

&lt;p&gt;在slack里记录今天完成的事跟明天要做的事，跟人约时间讨论问题，第二次查看邮箱并回复邮件。&lt;/p&gt;

&lt;p&gt;6:30PM-8:00PM&lt;/p&gt;

&lt;p&gt;做饭吃饭，把pocket里存的文章用读文章模式去听。&lt;/p&gt;

&lt;p&gt;8:00PM-10:00PM&lt;/p&gt;

&lt;p&gt;继续公开课学习或读书，twitter上看看学术圈出没出事或者更新下自己博客介绍下刚发表的论文。每天这个时间的内容可以不重样，不论学习还是探索都无所谓。如果你长期保持一个学习探索习惯，你会发现每天能带来新知识的东西其实并不多，大都是各类老调重弹。&lt;/p&gt;

&lt;p&gt;作为一个研究人员，要学会跟互联网打交道，最好有个人网站或课题组网站（可以用blogdown快速搭建）与在线简历，不要总想着构建学术声誉，也可以考虑知识的传播，例如系统总结前沿科学问题，用bookdown做成一本各章节不断更新的书，用xaringan制作网页格式的教案幻灯片公布到网站上，会议报告可以上传到slideshare上。&lt;/p&gt;

&lt;p&gt;其实研究人员首先是人，在遇到问题时用谷歌百度也比较常见，如果经常看到你的东西无形中也形成了你的声誉。同时，虽然现在PI都是40岁以上的，但终究会成为80、90后这一代人的，而这一代人是伴随互联网成长的，其认知过程很依赖网上资源，所以类似quora、stackoverflow、reddit、知乎、果壳、科学网等网站都在实质上累积着科研人员的声誉，我就见过MIT一个课题组定向招博后，招到了还发个课题组新闻说我们欢迎XX领域的guru加入课题组，而那个被招的博后也确实在博士阶段就在在线社区里名声响当当了，而其博士毕业的研究所跟MIT完全不在一个水平上。&lt;/p&gt;

&lt;p&gt;10:00PM-12:00AM&lt;/p&gt;

&lt;p&gt;完全休息娱乐时间，玩局游戏，健个身，看个电影，刷个微博，看看朋友圈点个赞，每天的缓冲时间，然后就可以睡了。&lt;/p&gt;

&lt;p&gt;其实互联网一直在潜移默化地改变着很多行业，自然包括科研，熟练运用这些工具可能会获得效率上的提升并减轻焦虑感。我有时甚至在想，其实有远见的课题组应该可以开个公众号的，一方面传播自己成果，另一方面可以推送领域内新论文，要知道相比看综述，看推送更轻松，而且形成习惯后也能形成学科内大局观甚至引导科研前沿，这可比跑到一两年一次的学科内大会上听报告或做报告效果强得多。其实国外用twitter与hashtag就可以了，甚至有专门网站评价科研人员在社交网络影响力的，这种类型的影响力不容小觑，别忘了给科研人员发钱的人或许会看学术期刊，但一定会刷朋友圈。&lt;/p&gt;

&lt;p&gt;以上纯属胡扯，如有雷同，那就雷同吧。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>现代科研的兴起</title>
      <link>/cn/2017/01/22/modern-scientist/</link>
      <pubDate>Sun, 22 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/01/22/modern-scientist/</guid>
      <description>&lt;p&gt;今天先讲个论文故事，然后讨论下科研领域正在发生的信息化过程。&lt;/p&gt;

&lt;p&gt;2015年，在《美国国家科学院院刊》（也就是PNAS）上发表了一篇&lt;a href=&#34;http://www.pnas.org/content/112/49/15078.full.pdf&#34;&gt;论文&lt;/a&gt;，题目翻译过来是《提升中的21世纪中年非拉美裔美国白人的患病率与死亡率》。文章对比了1999年到2013年美国非拉美裔白人及拉美裔白人及六个发达国家（包括法国、德国、英国、加拿大、澳大利亚、瑞典）45到54岁人群的死亡率，发现只有非拉美裔美国白人的死亡率是在上升的，在进一步分析了死亡原因后，作者发现毒品、酒精中毒、自杀还有慢性肝硬化可能主导这种上升，同时教育水平越低，上升比例越快。&lt;/p&gt;

&lt;p&gt;这是一篇对左派跟右派都有利的文章，&lt;a href=&#34;https://www.nytimes.com/2015/11/09/opinion/despair-american-style.html&#34;&gt;左派&lt;/a&gt;认为是这些年福利政策减弱与传统宗教价值观的复兴造成的，加上这一段算是共和党小布什的主要执政期，自然锅是右派的。有意思的是，&lt;a href=&#34;https://www.nytimes.com/2015/11/08/opinion/sunday/the-dying-of-the-whites.html&#34;&gt;右派&lt;/a&gt;看到这个研究后也发话称这个锅恰恰是因为白人蓝领对工作、信仰还有家庭观念的缺失，而这个恰恰是传统宗教价值观所倡导的。好了我们不看左右互搏了，解释怎么来都行，但现象总该没问题吧？&lt;/p&gt;

&lt;p&gt;有问题。文章发表不久，知名话痨兼统计学家 Andrew Gelman 教授 在自己博客上对这个研究的数据进行了&lt;a href=&#34;http://andrewgelman.com/2015/11/06/correcting-rising-morbidity-and-mortality-in-midlife-among-white-non-hispanic-americans-in-the-21st-century-to-account-for-bias-in/&#34;&gt;重新分析&lt;/a&gt;，其实说“重新分析”是书面说法，真实的情况是对这一组数据进行了校正。因为 Gelman 教授注意到了一个简单到不能再简单的问题：你这个死亡率没有对年龄分布进行校正。&lt;/p&gt;

&lt;p&gt;原始数据：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/usnwm1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;我来解释下这个校正，举例来说我有100个人年龄段在45到54岁，那么在这个15年的研究时间段里，每一年进入这个年龄段的人数应该是差不多一样的才好跟其他的地方去比。但恰恰这个年龄段包括了二战后的婴儿潮，也就是说，每年这个死亡率的基数在变，该年龄段整体平均年龄被拖大了，按照自然规律，年龄大本来就死亡率高。所以应该对每一年的数据除以其人数，也就是认为这个年龄段的人数应该差不多才合适。&lt;/p&gt;

&lt;p&gt;校正后数据：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/usnwm2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;额，从这个结果上看那个上升趋势就不明显了。 Gelman 教授进一步分析了其他国家数据，发现其他国家同年龄段死亡率校正后还是一直下跌，那么美国非拉美裔中年白人比较诡异的死亡率确实是存在的，也就是说原文主要结论没啥问题。然后Gelman 教授又想到会不会性别上有差异？然后得到了下面这个图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/usnwm3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;感情白人男性其实没怎么变，女性死亡率倒是一直在提高。然后Gelman 教授又计算了一下相对死亡率，用1999年为基准，看了下不同年龄段的&lt;a href=&#34;http://www.slate.com/blogs/bad_astronomy/2017/01/20/if_you_need_to_find_some_strength_saturn_s_moon_daphnis_may_help.html&#34;&gt;分布&lt;/a&gt;：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/usnwm4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;结果发现不仅仅45-54岁女性非拉美裔白人死亡率在上升，35-44岁这个年龄段也在上升。那么问题来了，为什么当初不去说这个年龄段呢？会不会原文属于一种发表歧视呢？也就是说对比了半天终于发现了一个显著的，而其实如果在处理数据时男女分开，这篇报道的题目会不会就成了“35-54岁女性非拉美裔白人死亡率在上升”呢？&lt;/p&gt;

&lt;p&gt;其实我讲这个故事对这个论文事实兴趣不大，我很好奇的是为什么这样的评论是以博客的形式出现的。传统学术界的交流一般依赖期刊论文与会议，但是动辄几个月的审稿时间是不是对成果交流的一种阻碍呢？诚然学术界绝大多数是要依赖出版物来获取声望，但其实有时候很多博客评论的深度与广度可能并不比3-5个审稿人的审稿意见低。&lt;/p&gt;

&lt;p&gt;回到这个案例，原论文的作者在另一个科学博客里回应了&lt;a href=&#34;http://nymag.com/scienceofus/2015/11/gender-controversy-over-white-mortality.html&#34;&gt;质疑&lt;/a&gt;，她声称研究过程中确实也考察了性别影响，但没有使用相对死亡率，为了不让读者被一大堆图表覆盖就没放到文章里。同时针对Gelman教授的论点，她重新分析后认为吸烟与否对这个年龄段男性女性死亡率差异起了重要贡献。但是她又说了如下的话：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We spent a year working on this paper, sweating out every number, sweating out over what we were doing, and then to see people blogging about it in real time — that’s not the way science really gets done&amp;hellip; . And so it’s a little hard for us to respond to all of the blog posts that are coming out&amp;hellip; . And if this is all people shooting from the hip, I don’t think that’s any way to move science forward, to move the research forward.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;也就是说，你们博客评论太草根，懒得理你。但数据的产生者或科学问题的提出者不应该同时也要是问题的正确解决者，有时候提供一个视角就很好了。可了解Gelman教授的人应该清楚，其哥伦比亚大学资深话唠身份不是白拿的，他马上就在博客上&lt;a href=&#34;http://andrewgelman.com/2015/11/15/why-is-it-so-hard-for-them-to-acknowledge-a-correction/&#34;&gt;回应&lt;/a&gt;了这样一封应该来自作者的虚构的信来表明博客这种交流方式其实也应该被科研人员尊敬而不是故作清高姿态：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We spent a year working on this paper, sweating out every number, sweating out over what we were doing, and we’re happy to see see people blogging about it in real time.&lt;/p&gt;

&lt;p&gt;We very much appreciate the effort put in by Laudan Aron, Lisa Dubay, Elaine Waxman, and Steven Martin, Philip Cohen, and Andrew Gelman to uncover the aggregation bias in our analysis, to correct for that bias, and to explore subtleties that we did not have a chance to get into in our paper. As Gelman noted, these corrections are in no way a debunking of our work—our comparisons of non-Hispanic American whites to groups in other countries and other ethnic groups still stand.&lt;/p&gt;

&lt;p&gt;We think it’s great that, after our paper was published in PNAS, it was possible to get rapid feedback. Had it not been for bloggers, we’d still be in the awkward situation of people trying to trying to explain an increase in death rates which isn’t actually happening. We join Paul Krugman and Ross Douthat in thanking these bloggers for their unpaid efforts on the behalf of everyone interested in this research. We count ourselves lucky to live in an era in which mistakes can be corrected rapidly, so that we and others do not have to wait months or even years for published corrections which themselves could contain further errors.&lt;/p&gt;

&lt;p&gt;As economists, we recognize that research work is always provisional, and that anyone studying the real world of human interactions has to accept that mistakes are part of the process. It is only through the efforts of our entire research community—publishing in journals, publishing in blogs, through informal conversations, whatever—that we move toward the truth. We always considered our PNAS paper to be just a single step in this process and we are glad that others have taken the trouble to correct some of our biases and omissions.&lt;/p&gt;

&lt;p&gt;Again, we thank the many researchers who have taken a careful look at our analyses. It’s good to know that our main findings are not affected by the corrections, we welcome further research in this area, and we hope that future discussion of our work, both in the scientific literature and in the popular press, make use of the corrected, age-adjusted trends.&lt;/p&gt;

&lt;p&gt;– Sincerely, Anne Case and Angus Deaton&lt;/p&gt;

&lt;p&gt;P.S. We have heard some people criticize the researchers noted above because they published their work in blogs rather than in peer-reviewed journals. We would never make such a silly, uninformed criticism. Since appearing in print, our work has received a huge amount of publicity. And, to the extent that we made mistakes or did not happen to explain ourselves clearly enough, it is the responsibility of others to publish their corrections and explanations as rapidly as possible. Blogs are a great way to do this. Blogs, unlike newspaper interviews, allow unlimited space to develop arguments and to present graphs of data. And we are of course aware that peer-reviewed journals make mistakes too. We published our paper in the Proceedings of the National Academy of Sciences, a journal that last year published a notorious paper on himmicanes and hurricanes, another discredited paper claiming certain behavior by people whose ages end in 9, and another paper on demographics which neglected to apply a basic age adjustment. So, yes, publication in journals is fine, but we very much welcome researchers who are willing to stick out their necks and correct the record in real time on blogs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;当然，Gelman教授的火爆脾气自然也会招来一些&lt;a href=&#34;http://noahpinionblog.blogspot.ca/2015/11/gelman-vs-case-deaton-academics-vs.html&#34;&gt;不满&lt;/a&gt;，但是我认为有些观点是很有益处的。&lt;/p&gt;

&lt;p&gt;博客，作为一种快速的回应方式，理应被尊重，因为科学发展就是要依赖这样的过程才能快速进步。说白了，现代科学研究不再是躲在黑暗小实验室里的勤勉钻研，更应该是一个交流碰撞的过程。最近几年，预印本服务器已经在物理、计算机跟生命科学领域大力发展，很多科研报道的记者跟前沿课题组都盯着。同时，基于博客还有微博（当然不是你熟悉的那个娱乐版）对科研成果的讨论也逐渐成为一种风气。数据共享、媒体传播、在线学术档案也逐渐成为青年科学家累积学术声誉、寻找业界合作的方法。严肃的学术讨论可以发生在任何地方，态度而不是场景产生严肃感。我们可以逐渐看到：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;大量高质量的问答、博文及报告幻灯片共享其实正在自发地形成一本本最新的网络教材&lt;/li&gt;
&lt;li&gt;计算机领域里最新的算法很快就会有博文告诉你如何去用并出现一个对应的github repo&lt;/li&gt;
&lt;li&gt;这边刚上传了一个物种基因组数据，那边某课题组集群上的自动化脚本就能生成一份报告email到课题组成员的邮箱里&lt;/li&gt;
&lt;li&gt;微博上传阅的最新研究成果很快就被reddit上的匿名专家进行了通俗化解读与评论并发现了新现象&lt;/li&gt;
&lt;li&gt;某公司苦苦追寻的最新技术操作过程竟然在直播平台被前沿科研人员作为论文发表的一部分所展示&lt;/li&gt;
&lt;li&gt;某个博士生意外收到某大牛课题组长的报告邀请，只因为他读了这个学生的博客，感觉他对某个领域的理解很有特色&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;你可以躲在象牙塔里不知道，但这一切都在发生，或许它目前不“正式”，但解决科学问题更应该依赖快速的良性公开交流而不是论文被发表，那终归只是个起点，现代化的科研方式正在兴起。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Statistical uncertainty of Isotope Ratio</title>
      <link>/en/2017/01/15/sd-isotope-ratio/</link>
      <pubDate>Sun, 15 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/en/2017/01/15/sd-isotope-ratio/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;



&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;!-- BLOGDOWN-BODY-BEFORE --&gt;

&lt;!-- /BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;In Analytical Chemistry, the measurements of isotope ratios are commons. However, I found the uncertainty of ratios are always shown in the format of standard deviation of independant vairiable, which is inappropriate in statistic. You accually measure at least two values to get one measurement.&lt;/p&gt;
&lt;p&gt;In fact, if you want to use the differences of isotope ratios as a measurement for certain process, you need to accept the assumption that the intensities of different isotopes are independant. Then we could make the Taylor series expansion of the ratio x/y around the mean of x and y:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{split} 
\frac{x}{y} \approx \frac{x}{y}\Big|_{\mu_x,\mu_y}&amp;amp;+(x-\mu_x)\frac{\partial}{\partial x}\Big(\frac{x}{y}\Big)\Big|_{\mu_x,\mu_y}+(y-\mu_y)\frac{\partial}{\partial y}\Big(\frac{x}{y}\Big)\Big|_{\mu_x,\mu_y}\\&amp;amp;+\frac{1}{2}(x-\mu_x)^2\frac{\partial^2}{\partial x^2}\Big(\frac{x}{y}\Big)\Big|_{\mu_x,\mu_y}+\frac{1}{2}(y-\mu_y)^2\frac{\partial^2}{\partial y^2}\Big(\frac{x}{y}\Big)\Big|_{\mu_x,\mu_y}+(x-\mu_x)(y-\mu_y)\frac{\partial^2}{\partial x \partial y}\Big(\frac{x}{y}\Big)\Big|_{\mu_x,\mu_y}\\&amp;amp;+\mathcal{O}\Big(\Big((x-\mu_x)\frac{\partial}{\partial x}+(y-\mu_y)\frac{\partial}{\partial y}\Big)^3\Big(\frac{x}{y}\Big)\Big)
\end{split}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The expectation of the ratio is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mathbb{E}[r] = \mathbb{E}\Big[\frac{\bar x}{\bar y}\Big] = \frac{\mu_x}{\mu_y} + Var(\bar y)\frac{\mu_x}{\mu_y^3} - \frac{Cov(\bar x,\bar y)}{\mu_y^2} \approx \frac{\mu_x}{\mu_y} + \frac{1}{n}\Big(Var(y)\frac{\mu_x}{\mu_y^3} - \frac{Cov(x,y)}{\mu_y^2}\Big)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The variance of the ratio is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{split}
Var(r) &amp;amp;= Var\Big( \frac{\bar x}{\bar y} \Big) = \mathbb{E}\Big[\Big(\frac{\bar x}{\bar y} - \mathbb{E}\Big[\frac{\bar x}{\bar y}\Big]\Big)^2\Big] \\&amp;amp;\approx \mathbb{E}\Big[\Big(\frac{\bar x}{\bar y} - \frac{\mu_x}{\mu_y}\Big)^2\Big]\\&amp;amp;\approx \mathbb{E}\Big[\Big((\bar x-\mu_x)\frac{\partial}{\partial \bar x}\Big(\frac{\bar x}{\bar y}\Big)\Big|_{\mu_x,\mu_y} + (\bar y - \mu_y)\frac{\partial}{\partial \bar y}\Big(\frac{\bar x}{\bar y}\Big)\Big|_{\mu_x,\mu_y}\Big)^2\Big]\\&amp;amp;\approx\frac{Var(\bar x)}{\mu^2_y} + \frac{\mu^2_x Var(\bar y)}{\mu^4_y} - \frac{2\mu_x Cov(\bar x, \bar y)}{\mu^3_y}\\&amp;amp;\approx\frac{1}{n}\Big(\frac{Var(x)}{\mu^2_y} + \frac{\mu_x^2 Var(y)}{\mu^4_y} - \frac{2\mu_x Cov(x,y)}{\mu^3_y}\Big)
\end{split}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Such values could be used as the uncertainty of the isotope ratios instead of the standard deviation of the ratios themselves.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>鸢尾花数据集背后的故事</title>
      <link>/cn/2017/01/15/iris-dataset/</link>
      <pubDate>Sun, 15 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/01/15/iris-dataset/</guid>
      <description>&lt;p&gt;如果说对机器学习或统计学习里最常见的示例数据集进行排序，那么鸢尾花数据集一定排的上号，而且不同于事后诸葛的泰坦尼克生还者数据，这个数据集理论上是可以拿来做预测的。设想某个清晨，你漫步花园并驻足于一朵鸢尾花前，然后你掏出尺子，测量了花萼长度、花萼宽度、花瓣长度跟花瓣宽度后静默片刻，淡淡的说到：“果然又是个维吉尼亚鸢尾。”留下一堆路人甲风中凌乱。&lt;/p&gt;

&lt;p&gt;但其实你是做不到的，新西兰统计学家Thomas Lumley最近发表了一篇&lt;a href=&#34;http://notstatschat.tumblr.com/post/155194690691/the-iris-data&#34;&gt;文章&lt;/a&gt;认为，这个数据集其实是Fisher或Anderson拿来想让读者做线性判别或无监督聚类的，而在真实的野外环境中，花从来都不是一个良好的种属判断条件而是探索一个假设的论据。。&lt;/p&gt;

&lt;p&gt;现在我们来看看当年究竟是为什么发布这个数据集。Anderson于1936年在《Annals of the Missouri Botanical Garden》上
发表了一篇题为《The Species Problem in Iris》的论文，不得不说我很少读到80年陈酿的论文，特别是这种用52页长篇大论讨论一个种属分类的，还没有摘要。&lt;/p&gt;

&lt;p&gt;文章第二章开头就给出了野外判断鸢尾花种属的判据：&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/iris1.png&#34; alt=&#34;plot of chunk null&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从里面我们可以看到，三种鸢尾花的基本判据其实是种子，至于花瓣也可以用。但作者也明确提出，由于非常容易枯萎，对花的测量数据用在分类上并不可靠，甚至良好的保存手段都没有。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/iris2.png&#34; alt=&#34;plot of chunk null&#34; /&gt;&lt;/p&gt;

&lt;p&gt;然而，作者通过5年的观察研究认为Iris versicolor 跟 Iris virginica 各自种类内部其实变化很大，但本质上还是不一样，作者就用两个英格兰小村庄作为对比，一个在砂石地上，另一个在石灰岩上，其建筑风格也许差不多，但建材不一样，所以无论如何都不一样。但随后作者提出，导致这一现象的原因很有可能是因为其中有一种是二倍体，所以形态上虽然像，但就不是一个种，“A simple hypothesis immediately sugguested itself”。为了说明这一点，Iris setosa登场了，因为这一类分布比较靠北，个头比较小，所以很有可能Iris versicolor是Iris setosa跟Iris virginica的杂合体。为了验证这个假设，作者依赖染色体个数的测量与花瓣花萼等数据，推测Iris versicolor与Iris virginica的亲缘关系要近于其与Iris setosa的距离，两者距离大概1:2。也就是说，在原始文献中，花的测量数据并不是用来分类而是用来计算三个物种间亲缘关系的。&lt;/p&gt;

&lt;p&gt;其实Fisher在&lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1111/j.1469-1809.1936.tb02137.x/full&#34;&gt;公布这个数据集&lt;/a&gt;时也说的很明确，这些测量数据就是来说明Iris versicolor是Iris virginica与Iris setosa的中间类型，拿来实际分类不靠谱。虽然Fisher自己就是拿这些数据搞了一个线性判别分析。而线性判别分析的实质是认为花的测量数据是来自于不同的分布，通过计算分布参数来进行区别。说的更像人话一点就是我对四个测量值进行一种线性变换，目的是让这种线性变化可以很好的区别三个分类。既然是线性变换最终还是会得到一个预测值，衡量三个分类这个预测值之间的距离就可以进行其关系的推测。结果自然是确认了1:2这个比例，而且后续的研究也在16sRNA上确认了这个发现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/iris3.png&#34; alt=&#34;plot of chunk null&#34; /&gt;&lt;/p&gt;

&lt;p&gt;其实从这个数据集的故事是我们可以清晰感觉到的不是一个统计学过程而是科研过程。从观察到提出假说，然后通过数据分析给出证据，最后通过后续的研究不断证明结论，从已知走向未知。而当今的很多研究，你很难找到假设检验的影子，更多偏重的是流程化科研，用更尖端的技术得到更准确的测量，然后甩给统计学家处理，缺少了最初的&amp;rdquo;insight&amp;rdquo;。或者说，相对专业的领域分工让科学家自己也变得工具化，缺少研究方法，特别是数据处理方法与实际问题的原理层互动从而将数据分析黑箱化与实用化，这不妨碍实际问题的解决，但会少很多发现的乐趣。&lt;/p&gt;

&lt;p&gt;当然，寻找insight可能是未来人工智能可以做的，但愿这一天晚点到来。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>高通量数据的多重检验问题</title>
      <link>/cn/2017/01/04/mutiple-test/</link>
      <pubDate>Wed, 04 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>/cn/2017/01/04/mutiple-test/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;



&lt;!-- /BLOGDOWN-HEAD --&gt;

&lt;!-- BLOGDOWN-BODY-BEFORE --&gt;

&lt;!-- /BLOGDOWN-BODY-BEFORE --&gt;

&lt;p&gt;各种组学分析技术的进展导致了我们在收集数据时更侧重数据信息的保存，然而我们收集的数据最终也会根据我们的想探索的问题来寻找答案，甚至有时候我们在实验设计分组时就打算考察某一个变量而为了获取更多的相关信息而采用了组学技术。这点是尤其要强调的，科研人员一定是面向科学问题解决科学问题，而不要为了应用新技术而应用新技术。当然，现实的情况是新技术特别是组学技术的发展为我们提供了大量的可同时测定的生物学指标（例如基因表达水平、蛋白表达水平、代谢产物表达水平）数据，大到我们事先也不知道会有什么模式会出现，这样就需要数据挖掘，特别是统计学知识来帮助我们发现新知。然而，组学技术产生的这类高通量数据是具有一些特质的，数据里确实会有我们关心分组的差异表达，但同时也有大量测量值对于我们设定的分组不敏感，然而当我们去对比组间差异时就会被这些数据干扰。&lt;/p&gt;
&lt;p&gt;举例而言，我对两组样品（暴露组跟对照组）中每一个样品测定了10000个指标，每组有10个样品，那么如果我想知道差异有多大就需要对比10000次，具体说就是10000次双样本t检验。那么如果我对t检验的置信水平设置在0.05，也就是5%假阳性，做完这10000次检验，我会期望看到500个假阳性，而这500个有显著差异的指标其实对分组不敏感也可以随机生成。假如真实测到了600个有显著差异的指标，那么如何区分其中哪些是对分组敏感？哪些又仅仅只是随机的呢？随机的会不会只有500个整呢？&lt;/p&gt;
&lt;p&gt;这就是多重检验问题，做经典科研实验时往往会忽略，深层次的原因是经典的科研实验往往是理论或经验主导需要进行检验的假说。例如，我测定血液中白血球的数目就可以知道你是不是处于炎症中，其背后是医学知识的支撑。然而，再组学或其他高通量实验中，研究实际是数据导向的，也就是不管有用没用反正我测了一堆指标，然后就去对比差异，然后就是上面的问题了，我们可能分不清楚哪些是真的相关，哪些又是随机出现的。&lt;/p&gt;
&lt;p&gt;当然这个问题出现也不是一天两天了，再&lt;a href=&#34;http://yufree.cn/blogcn/2013/12/16/rgabriel-package.html&#34;&gt;多重比较&lt;/a&gt;问题上就已经被提出过，只不过在多重比较里对比数因为排列组合比较多而在多重检验里纯粹就是因为同时进行的假设检验数目多。那么其实从统计角度解决的方法也基本来源于此。&lt;/p&gt;
&lt;div id=&#34;family-wise-error-rate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;整体错误率（Family-wise error rate）控制&lt;/h2&gt;
&lt;p&gt;对于单次比较，当我们看到显著差异的p值脑子里想的是空假设为真时发生的概率，当我们置信水平设定在0.95（I型错误率0.05）而p值低于对应的阈值，那么我们应该拒绝空假设。但对比次数多了从概率上就会出现已经被拒绝的假设实际是错误的而你不知道是哪一个。整体错误率控制的思路就是我不管单次比较了，我只对你这所有的对比次数的总错误率进行控制。还是上面的例子，对于10000次假设检验我只能接受1个错误，整体犯错概率为0.0001，那么对于单次比较，其I型错误率也得设定在这个水平上去进行假设检验，结果整体上错误率是控制住了，但对于单次比较就显得十分严格了。下面用一个仿真实验来说明：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 随机数的10000次比较
set.seed(42)
pvalue &amp;lt;- NULL
for (i in 1:10000){
  a &amp;lt;- rnorm(10)
  b &amp;lt;- rnorm(10)
  c &amp;lt;- t.test(a,b)
  pvalue[i] &amp;lt;- c$p.value
}
# 看下p值分布
hist(pvalue)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/null-1.png&#34; alt=&#34;plot of chunk null&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;plot of chunk null&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 小于0.05的个数
sum(pvalue&amp;lt;0.05)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 477&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 小于0.0001的个数
sum(pvalue&amp;lt;0.0001)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这样我们会看到进行了整体的控制之后，确实是找不到有差异的了，但假如里面本来就有有差异的呢？&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42)
pvalue &amp;lt;- NULL
for (i in 1:10000){
  a &amp;lt;- rnorm(10,1)
  b &amp;lt;- a+1
  c &amp;lt;- t.test(a,b)
  pvalue[i] &amp;lt;- c$p.value
}
# 看下p值分布
hist(pvalue)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/diff-1.png&#34; alt=&#34;plot of chunk diff&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;plot of chunk diff&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 小于0.05的个数
sum(pvalue&amp;lt;0.05)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 6559&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 小于0.0001的个数
sum(pvalue&amp;lt;0.0001)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 45&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面我们模拟了10000次有真实差异的假设检验，结果按照单次检验0.05的阈值能发现约7000有差异，而使用0.0001却只能发现不到100次有显著差异。那么问题很明显，或许控制整体错误率可以让我们远离假阳性，但假阴性也就是II型错误率就大幅提高了，最后的结果可能是什么差异也看不到。&lt;/p&gt;
&lt;p&gt;下面我们尝试一个更实际的模拟，混合有差异跟无差异的检验：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42)
pvalue &amp;lt;- NULL
for (i in 1:5000){
  a &amp;lt;- rnorm(10,1)
  b &amp;lt;- a+1
  c &amp;lt;- t.test(a,b)
  pvalue[i] &amp;lt;- c$p.value
}
for (i in 1:5000){
  a &amp;lt;- rnorm(10,1)
  b &amp;lt;- rnorm(10,1)
  c &amp;lt;- t.test(a,b)
  pvalue[i+5000] &amp;lt;- c$p.value
}
# 看下p值分布
hist(pvalue)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/mix-1.png&#34; alt=&#34;plot of chunk mix&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;plot of chunk mix&lt;/p&gt;
&lt;/div&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 小于0.05的个数
sum(pvalue&amp;lt;0.05)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3499&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 小于0.0001的个数
sum(pvalue&amp;lt;0.0001)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 21&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此时结果就更有意思了，明明应该有5000次是有差异的，但阈值设定在0.05只能看到约3500次，而0.0001只能看到24次。&lt;/p&gt;
&lt;p&gt;上面的模拟告诉我们，降低假阳性会提高假阴性的比率，而且似乎本来0.05的阈值对于真阳性也是偏小的。同时，面对假设检验概率低于0.05的那些差异，我们也没有很好的方法区别哪些是真的，哪些是随机的。&lt;/p&gt;
&lt;p&gt;其实很多人都知道整体错误率控制是比较严格的，但也不是完全没人用，例如寻找生物标记物做重大疾病诊断时就不太能接受假阳性而可以接受一定的假阴性，此时如果标准放宽就会找到一大堆假信号，到时候标记不准就会对诊断产生负面影响。&lt;/p&gt;
&lt;p&gt;下面介绍下常见的整体错误率控制方法：&lt;/p&gt;
&lt;div id=&#34;bonferroni-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bonferroni 方法&lt;/h3&gt;
&lt;p&gt;思路很简单，就是控制显著性，例如单次检验假阳性比率&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;控制在0.05，那么n次检验假阳性比率控制为&lt;span class=&#34;math inline&#34;&gt;\(\frac{\alpha}{n}\)&lt;/span&gt;。这样实际是对整体采用了个体控制的控制思路：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
P(至少一个显著)=1-P(无显著差异) = 1-(1-\alpha/n)^n
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;我们来看下&lt;span class=&#34;math inline&#34;&gt;\(\alpha = 0.05\)&lt;/span&gt;随比较数增加的效果：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- c(1:10 %o% 10^(1:2))
p0 &amp;lt;- 1-(1-0.05)^n
p &amp;lt;- 1-(1-0.05/n)^n
# 不进行控制
plot(p0~n,ylim = c(0,1))
# Bonferroni方法控制
points(p~n,pch=19)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/Bonferroni-1.png&#34; alt=&#34;plot of chunk Bonferroni&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;plot of chunk Bonferroni&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;其实，这样的控制得到的整体错误率是略低于0.05的，并且数目越大，整体错误率越低。这个方法十分保守，有可能什么差异你都看不到，因为都变成假阴性了。在实际应用中一般不调节p值的假阳性比率而直接调节p值，取原始p值跟整体检验数目的乘积与1的最小值作为调节p值，还可以用0.05或0.01进行判断，不过这时候控制的整体而不是单一检验了。&lt;/p&gt;
&lt;p&gt;当然这只是最原始的Bonferroni方法，后来Holm改进了这种一步法为逐步法，此时我们需要首先对原始p值进行排序，然后每个原始p值乘上其排序作为调节p值。例如三次多重检验的p值分别是0.01、0.03与0.06，其调节后的p值为0.03，0.06，0.06。如果我们控制整体假阳性比率低于0.05，那么调解后只有第一个检验可以拒绝空假设。值得注意的是Holm的改进是全面优于原始方法的，也就是说当你一定要去用Bonferroni方法控制整体错误率，优先选Holm的改进版。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sidak-&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sidak 方法&lt;/h3&gt;
&lt;p&gt;上面那种方法其实有点非参的意思，其实数学上我们是可以精确的把假阳性比率控制在某个数值的：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
P(至少一个显著)=1-P(无显著差异) = 1-(1-\alpha&amp;#39;)^n = 0.05
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;求解可得到&lt;span class=&#34;math inline&#34;&gt;\(\alpha&amp;#39; = 1-0.95^{\frac{1}{n}}\)&lt;/span&gt;，此时我们就可以比较精确的控制整体错误率了，但是，这个方法有个前提就是各个检验必须是独立的，这在生物学实验里几乎不可能，所以这个方法的应用远没有Bonferroni方法广。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;false-discovery-rate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;错误发现率（False Discovery Rate）控制&lt;/h2&gt;
&lt;p&gt;刚才的模拟中我们可以看到，控制整体错误率比较严格，假阴性比率高，那么有没有办法找到假阴性比率低的呢？要知道我们其实只关心有差异的那部分中那些是真的，哪些是假的，无差异的可以完全不用考虑。那么我们可以尝试控制错误发现率，也就是在有差异的那一部分指标中控制错误率低于某一水平。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 所有有差异的
R &amp;lt;- sum(pvalue&amp;lt;0.05)
# 假阳性
V &amp;lt;- sum(pvalue[5001:10000]&amp;lt;0.05)
# 错误发现率
Q &amp;lt;- V/R
R&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3499&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 225&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Q&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.06430409&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面的计算显示虽然我们漏掉了很多阳性结果，但错误发现率并不高。事实上如果我们控制错误率到0.01，错误发现率会更低：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# 所有有差异的
R &amp;lt;- sum(pvalue&amp;lt;0.01)
# 假阳性
V &amp;lt;- sum(pvalue[5001:10000]&amp;lt;0.01)
# 错误发现率
Q &amp;lt;- V/R
R&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 999&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;V&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 34&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Q&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.03403403&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其实出现这个问题不难理解，空假设检验里p值是均匀分布的而有差异检验的p值是有偏分布且偏向于较小的数值，所以假阳性控制的越小，有偏分布占比例就越高，但同时会造成假阴性提高的问题。&lt;/p&gt;
&lt;p&gt;那么错误发现率会不会比整体错误率的控制更好呢？这里通过两种常见的控制方法进行说明。&lt;/p&gt;
&lt;div id=&#34;benjamini-hochberg&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Benjamini-Hochberg方法&lt;/h3&gt;
&lt;p&gt;这个方法跟Holm方法很像，也是先排序，但之后p值并不是简单的乘排序，而是乘检验总数后除排序：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
p_i \leq \frac{i}{m} \alpha
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;举例来说就是假设三次多重检验的p值分别是0.01、0.03与0.06，其调节后的p值为0.03，0.45，0.06。那么为什么说这种方法控制的是错误发现率呢？我们来看下&lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;是如何得到的：p值乘总数m得到的是在该p值下理论发现数，而除以其排序实际是该p值下实际发现数，理论发现数基于在这里的分布是均匀分布，也就是空假设的分布，这两个的比值自然就是错误发现率。下面我用仿真实验来说明一下：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbh &amp;lt;- p.adjust(pvalue,method = &amp;#39;BH&amp;#39;)
ph &amp;lt;- p.adjust(pvalue,method = &amp;#39;holm&amp;#39;)
plot(pbh~pvalue)
points(ph~pvalue,col=&amp;#39;red&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/BH-1.png&#34; alt=&#34;plot of chunk BH&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;plot of chunk BH&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;从上面图我们可以看出，如果控制整体错误率（红色），那么p值很容易就到1了，过于严格。而如果用BH方法控制错误发现率，那么原始p值越大，调节后的错误发现率也逐渐递增，这就符合了区分真实差异与随机差异就要假设真实差异更可能出现更小的p值这个现象。当然至于这个方法的推演细节，可以去读原始论文。值得注意的是这个错误发现率求的是有差异存在的情况，不然零发现就出现除数为零了。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;storeyq&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Storey方法（q值）&lt;/h3&gt;
&lt;p&gt;如果说BH方法还算是调节了p值，那么Storey提出的方法则直接去估计了错误发现率本身。刚才介绍BH算法时我提到总数m与p值的乘积是基于这里的分布是均匀分布，但实际上按照错误发现率的定义，这里应该出现的是空假设总数。直接使用所有检验数会造成一个问题，那就是对错误发现率的高估，为了保证功效，这里应该去估计空假设的总体比例。这里我们去观察混合分布会发现在p值较大的时候基本可以认为这里分布的都是空假设的p值，那么我们可以用：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\hat\pi_0 = \frac{\#\{p_i&amp;gt;\lambda\}}{(1-\lambda)m}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;估计这个比例&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi_0\)&lt;/span&gt;，其中参数&lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;的跟&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi_0\)&lt;/span&gt;的关系可以用一个三阶方程拟合，然后计算出整体假阳性比例。有了这个比例，我们再去按照BH方法计算p值，然后两个相乘就会得到q值，而q值的理论含义就是在某一概率上低于这个概率所有数里假阳性的比重。打个比方，我测到某个指标的q值是0.05，这意味着q值低于这个数所有检验中我有0.05的可能性得到的是假阳性。。但我们会发现当空假设比重较高时BH结果跟q值很接近，而比重很低的话q值会变得更小，功效会提高，基本也符合我们对错误发现率的预期。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(qvalue)
q &amp;lt;- qvalue(pvalue)
# Q值
plot(q$qvalues~pvalue,col=&amp;#39;blue&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/qvalues-1.png&#34; alt=&#34;plot of chunk qvalues&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;plot of chunk qvalues&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;如上图所示，q值增大后会最终逼近到0.5，而我们的模拟中空假设的比例就设定就是50%。我们重新模拟一个空假设比例5%的实验：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42)
pvalue &amp;lt;- NULL
for (i in 1:500){
  a &amp;lt;- rnorm(10,1)
  b &amp;lt;- a+1
  c &amp;lt;- t.test(a,b)
  pvalue[i] &amp;lt;- c$p.value
}
for (i in 1:9500){
  a &amp;lt;- rnorm(10,1)
  b &amp;lt;- rnorm(10,1)
  c &amp;lt;- t.test(a,b)
  pvalue[i+500] &amp;lt;- c$p.value
}
pbh &amp;lt;- p.adjust(pvalue,method = &amp;#39;BH&amp;#39;)
ph &amp;lt;- p.adjust(pvalue,method = &amp;#39;holm&amp;#39;)
q &amp;lt;- qvalue(pvalue)
plot(pbh~pvalue)
# Holm 方法
points(ph~pvalue,col=&amp;#39;red&amp;#39;)
# Q值
points(q$qvalues~pvalue,col=&amp;#39;blue&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/qbh-1.png&#34; alt=&#34;plot of chunk qbh&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;plot of chunk qbh&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;此时我们可以看到两者结果较为接近，q值理论上更完备，功效也更强，但算法上对&lt;span class=&#34;math inline&#34;&gt;\(\hat\pi_0\)&lt;/span&gt;的估计并不稳定，特别是比例靠近1的时候，所以BH方法可能还是更容易让人接受的保守错误发现率控制。详细的估计方法还得去啃Storey的&lt;a href=&#34;http://www.pnas.org/content/100/16/9440.full&#34;&gt;论文&lt;/a&gt;。&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;section level2&#34;&gt;
&lt;h2&gt;小结&lt;/h2&gt;
&lt;p&gt;多重检验问题是高通量数据里逃不掉的问题，要想找出真正的差异数据就要面对假阳性跟假阴性问题，这是一个不可兼得的过程，看重假阳性就用整体错误率，看重功效就用错误发现率控制。并不是说哪种方法会好一些，更本质的问题在于你对实际问题的了解程度及统计方法的适用范围。例如你选基因芯片时实际也进行了一次选择，改变了整体检验的p值分布，而不同的p值分布对应的处理方法也不太一样，有兴趣可以读下&lt;a href=&#34;http://varianceexplained.org/statistics/interpreting-pvalue-histogram/&#34;&gt;这篇&lt;/a&gt;。有时候你的实验设计本身就会影响数据的统计行为，而这个恰恰是最容易被忽视的。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>尺度效应疑案</title>
      <link>/cn/2016/12/18/scale/</link>
      <pubDate>Sun, 18 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/cn/2016/12/18/scale/</guid>
      <description>&lt;p&gt;1947年，生物学家Max Kleiber 发表了一篇题为《body size and metabolic rate》的论文，在论文中提出了一个克莱伯定律：对于哺乳动物，其基础代谢速率与体重的3/4次幂成正比。这其实是个观察得出的规律，搭上眼一看可能觉得没什么，但其实问题就出在那个3/4上了：理论上不应该是3/4，而应该是2/3，而且从19世纪人们就认为应该是这个数。&lt;/p&gt;

&lt;p&gt;作为一个生物体，我们的物理构造受限于基本的物理规律，例如散热。生物一般具有细胞结构（病毒朊病毒就别来添乱了），对生物而言，维持正常的生理活动需要呼吸作用提供能量，当然也要有热量产生，前者可以用需氧量来衡量，后者自然跟前者成正比。那么能量供应与热量产生必然是要有一个平衡的，例如身躯庞大，能量供应多，热量也会多，如果热量不能及时散出去或者散热太快，那么细胞温度就无法维持，生理功能也就受到影响。那么能否用这个平衡构建一个代谢速率跟质量的简化模型描述呢？可以。&lt;/p&gt;

&lt;p&gt;我们把整个哺乳动物想象成一个直径为d的球，那么不考虑密度差异，球的质量跟体积是成正比的：&lt;/p&gt;

&lt;p&gt;质量正比于体积正比于d的立方&lt;/p&gt;

&lt;p&gt;同时，这个球的散热应该是跟表面积成正比的：&lt;/p&gt;

&lt;p&gt;表面积正比于d的平方&lt;/p&gt;

&lt;p&gt;散热跟代谢速率是成正比的，那么有：&lt;/p&gt;

&lt;p&gt;代谢速率 正比于 表面积 正比于 d平方 正比于 d立方的2/3次方 正比于 质量的2/3次方&lt;/p&gt;

&lt;p&gt;其实想象成立方体也不会改变结论，代谢速率与质量的对数作图，会得到斜率为2/3的直线。&lt;/p&gt;

&lt;p&gt;但克莱伯定律告诉我们（如下图的回归分析），这个数是3/4。
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/scale1.png&#34; alt=&#34;&#34; /&gt;
更有趣的是，不仅仅哺乳动物，如果你把低等生物甚至单细胞生物也考虑进来，这个斜率还是3/4：
&lt;img src=&#34;http://yufree.github.io/blogcn/figure/scale2.png&#34; alt=&#34;&#34; /&gt;
那么问题来了：上面哪个假设有问题呢？或者说怎么才能假设出一个3/4的尺度效应呢？这个问题等了50年才等到一个答案。&lt;/p&gt;

&lt;p&gt;1997年，James Brown 等人在science上发表了一篇题为《A General Model for the Origin of Allometric Scaling Laws in Biology》的论文，论文给出了一个基于生物体物质能量输送方式而简洁明了的解决方案，这个方案有三个基本假设：&lt;/p&gt;

&lt;p&gt;进化压力下，生物体倾向于使用耗能最少的方式来传递物质进行新陈代谢；&lt;/p&gt;

&lt;p&gt;如果要想把生物体用一种输送方式填满，最有效的就是有自我相似性的层级管道；&lt;/p&gt;

&lt;p&gt;只在输送管道的末端，营养与物质交换是跟体积相关的。&lt;/p&gt;

&lt;p&gt;如果你有一个三维实体，他需要各个部位都可以得到某一区域摄取的物质与能量，那么填充管道最节能的方法就是找一种有边界的输送方式，进化给我们的答案就是分形结构。我们的循环系统就是由动脉，静脉及毛细血管组成，这基本可以看作是分支结构。而对绿色植物而言，其物质输送方式是维管束，也可看作一种自我相似性的层级管道。最后一个假设是对计算最关键的，输送管道末端的物质能量交换对于各种生物体应该是相对一致的，但因为生物体大小不一致，层级数也就不一致，是这个联系了生物体质量与代谢速率。&lt;/p&gt;

&lt;p&gt;那么如何联系？考虑一个典型的分支结构，每个节点都是从一个分到n个，有m层，最底层会有n^m个分支，在这一层上已经不能再分了，或者说继续分也无法将物质能量输送到更多的空间里，这是分形的边界。而在分支的末端代谢速率是恒定的，如此有：&lt;/p&gt;

&lt;p&gt;代谢速率正比于末端分支个数&lt;/p&gt;

&lt;p&gt;那么末端分支个数跟生物体质量如何联系呢？从分形的角度看就是已知节点的分支策略，求解这样的分形能占据多大的体积，而体积也就跟质量正相关了。对一个具有自相似性的结构，子结构是母结构的重现，那么在一个空间里如何填充呢？首先子结构的长度应该是按照固定比例缩短的，其次子结构的内径也应该是按比例逐渐缩小的，James Brown设定前者的比例A跟分支数n的1/3次方成正比，后者的比例B跟分支数n的1/2次方成正比，而伸展空间的大小正比于A的平方乘B，那么有：&lt;/p&gt;

&lt;p&gt;质量正比于AB^2正比于分支个数的4/3次方&lt;/p&gt;

&lt;p&gt;如此有：&lt;/p&gt;

&lt;p&gt;代谢速率正比于末端分支数正比于质量的3/4次方&lt;/p&gt;

&lt;p&gt;相信你看完后会跟我有类似的感觉：这不是生造出来的吗？但其实还是有比较严密的推理的，感兴趣看原文，不感兴趣我大致说下思路。&lt;/p&gt;

&lt;p&gt;末端分支的体积正比于内径的平方乘上分支长度，总体积就是不同层级m上各个分支体积之和，而基于自相似性，求和后的总体积正比于不同层内径比例的平方乘不同层长度比例，这就是伸展空间大小正比于A的平方乘B的来源。&lt;/p&gt;

&lt;p&gt;那么底层分支长度跟高一层的分支长度的比例也就是A如何跟分支数产生联系呢？在分形结构末端，两层的分支总体积几乎相等，而每层分支体积可以看作分支长度为内径的球体体积乘个数，求比例可以发现分支长度比例的三次方（球体体积公式）等于节点的分支个数n，也就是A跟分支数n的1/3次方成正比。&lt;/p&gt;

&lt;p&gt;同理，分形里底层分支截面积之和等于上一层截面积之和，求比例可发现分支内经比例的平方（圆面积公式）等于节点的分支个数n，也就是B跟分支数n的1/2次方成正比。&lt;/p&gt;

&lt;p&gt;这样我们就得到了自然界中尺度效应里那个3/4。&lt;/p&gt;

&lt;p&gt;从假设为球体或立方体到思考体内物质能量交换过程，对一个客观事实给出合理解释是不容易的。但今天讲这个并不是说后面那个是对的，其实最新的实验证据并不能很好的区别到底是2/3跟3/4，各有各的解释空间。但这个研究是很具有启发性的，有限空间内部的有序物质能量交换可以说是生物体的一个特性，当初研究尺度效应的研究人员现在把研究手段放到了另一种“有机体”——城市上面。社交网络、交通规划、管道流控…总有些自发形成的规则等待人们去探索。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>水卢流水（二）</title>
      <link>/cn/2016/12/18/waterloo-ii/</link>
      <pubDate>Sun, 18 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/cn/2016/12/18/waterloo-ii/</guid>
      <description>&lt;p&gt;11
川普当选时作为学校还是很政治正确的嘲讽了一把美国人，但真要问他们移民过来怎么办？他们马上会说不行！这不是抢我们饭碗吗？&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/waterloo2.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;12&lt;/p&gt;

&lt;p&gt;课题组成员来自加村、波兰、意大利、阿根廷、哥伦比亚、伊朗、印度与中国，这不算刚跑路的法国烟民，跑到ratemyprofessor上去看老板评价，不出所料的差评，有一个原因是：He abused his grad student specially immigrant using his influence.&lt;/p&gt;

&lt;p&gt;13&lt;/p&gt;

&lt;p&gt;跟拉美同事交流，发现我们竟都是看着七龙珠等日漫长大的一代，反倒是加村土著，他们心心念念的是哈利波特。&lt;/p&gt;

&lt;p&gt;14&lt;/p&gt;

&lt;p&gt;老板每次开会都会放古典音乐并喝茶，原因是安抚他看到我们垃圾一样报告时烦躁的心情。对了，两周就要交一次报告。&lt;/p&gt;

&lt;p&gt;15&lt;/p&gt;

&lt;p&gt;开学时作为路盲申请了引路志愿者，活动结束时我基本搞清楚学校里的路了，只是苦了那些跟我瞎转的学生。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/waterloo1.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;16&lt;/p&gt;

&lt;p&gt;为了认识更多的中国人，参与了一个面向薄厚跟访学的英语课，主讲是个德国老太太，助教是她退休的英国老公，老两口从2002年开始开课，不收学费，也很敬业，学生多来自国内，哈工大居多，大概那边比较耐寒。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/waterloo4.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;17&lt;/p&gt;

&lt;p&gt;加村的资本主义已经发展到社会主义阶段了，五大银行三大电信基本垄断，收费贵的要死且落后，信用卡想自动还款需要打电话，按我的经验，每次交流大概半小时到一小时之间，其中有一大半时间是提示音，告诉你客服很忙，而且客服也颇有国营企业风范，甩锅技术一流，我的经验总结就是：能走邮件，就别在电话上浪费时间了。&lt;/p&gt;

&lt;p&gt;18&lt;/p&gt;

&lt;p&gt;当地华人论坛上总少不了让人从国内带东西的帖子，需求最旺盛的是烟，很多老烟鬼适应得了零下三四十度的鬼天气与语言环境，但吞云吐雾起来，都是乡愁。&lt;/p&gt;

&lt;p&gt;19&lt;/p&gt;

&lt;p&gt;一下雪，中国留学生的二代属性就不自觉的暴露了，满眼都是加拿大鹅极地科考的标志，当之无愧的雪龙号船员培训基地，起码制服统一了。不过暴雪临门时，路上昏昏沉沉，竟有种回到帝都吸霾的感觉。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/waterloo5.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;20&lt;/p&gt;

&lt;p&gt;年末学校发邮件请所有员工临时工吃午餐，本着蹭饭的目的去了，结果队伍奇长，想退出来结果已经有人跟你聊天做social了，好容易吃完走小道跑路，发现校长躲小道角落里休息，很亲切的握了手说welcome，等出门总觉得有点不对，大概是吃猪排搞了一手油，然后都蹭校长手上了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://yufree.github.io/blogcn/figure/waterloo3.JPG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>